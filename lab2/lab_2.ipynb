{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {
            "pycharm": {
               "name": "#%% md\n"
            }
         },
         "source": [
            "# Klasyfikacja niezbalansowana, klasyfikatory zespołowe i wyjaśnialna AI\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "pycharm": {
               "name": "#%% md\n"
            }
         },
         "source": [
            "## Wykorzystanie Google Colab\n",
            "\n",
            "Jeśli korzystasz z Google Colab skopiuj plik `feature_names.json` do katalogu głównego projektu.\n",
            "\n",
            "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/apohllo/sztuczna-inteligencja/blob/master/lab2/lab_2.ipynb)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "## Ładowanie i eksploracja danych\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Na tym laboratorium wykorzystamy zbiór danych [Polish companies bankruptcy](https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data). Dotyczy on klasyfikacji, na podstawie danych z raportów finansowych, czy firma zbankrutuje w ciągu najbliższych kilku lat. Jest to zadanie szczególnie istotne dla banków, funduszy inwestycyjnych, firm ubezpieczeniowych itp., które z tego powodu zatrudniają licznie data scientistów. Zbiór zawiera 64 cechy, obliczone przez ekonomistów, którzy stworzyli ten zbiór, są one opisane na podlinkowanej wcześniej stronie. Dotyczą one zysków, posiadanych zasobów oraz długów firm.\n",
            "\n",
            "Ściągnij i rozpakuj dane (`Data Folder` -> `data.zip`) do katalogu `data` obok tego notebooka. Znajduje się tam 5 plików w formacie `.arff`, wykorzystywanym głównie przez oprogramowanie Weka. Jest to program do \"klikania\" ML w interfejsie graficznym, jakiś czas temu popularny wśród mniej technicznych data scientistów. W Pythonie ładuje się je za pomocą bibliotek SciPy i Pandas.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Jeśli korzystasz z Linuksa możesz skorzystać z poniższych poleceń do pobrania i rozpakowania tych plików.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 79,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-10-17T12:09:50.173669Z",
               "start_time": "2023-10-17T12:09:24.311939Z"
            },
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "# !mkdir -p data\n",
            "# !wget https://archive.ics.uci.edu/static/public/365/polish+companies+bankruptcy+data.zip -O data/data.zip"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 80,
         "metadata": {
            "ExecuteTime": {
               "end_time": "2023-10-17T12:10:04.017260Z",
               "start_time": "2023-10-17T12:09:57.831756Z"
            },
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "# !unzip data/data.zip -d data"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "W dalszej części laboratorium wykorzystamy plik `3year.arff`, w którym na podstawie finansowych firmy po 3 latach monitorowania chcemy przewidywać, czy firma zbankrutuje w ciągu najbliższych 3 lat. Jest to dość realistyczny horyzont czasowy.\n",
            "\n",
            "Dodatkowo w pliku `feature_names.json` znajdują się nazwy cech. Są bardzo długie, więc póki co nie będziemy z nich korzystać.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 81,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "import json\n",
            "import os\n",
            "\n",
            "from scipy.io import arff\n",
            "import pandas as pd\n",
            "\n",
            "data = arff.loadarff(os.path.join(\"data\", \"3year.arff\"))\n",
            "\n",
            "with open(\"feature_names.json\") as file:\n",
            "    feature_names = json.load(file)\n",
            "\n",
            "X = pd.DataFrame(data[0])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "pycharm": {
               "name": "#%% md\n"
            }
         },
         "source": [
            "Przyjrzyjmy się teraz naszym danym.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 82,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>Attr1</th>\n",
                     "      <th>Attr2</th>\n",
                     "      <th>Attr3</th>\n",
                     "      <th>Attr4</th>\n",
                     "      <th>Attr5</th>\n",
                     "      <th>Attr6</th>\n",
                     "      <th>Attr7</th>\n",
                     "      <th>Attr8</th>\n",
                     "      <th>Attr9</th>\n",
                     "      <th>Attr10</th>\n",
                     "      <th>...</th>\n",
                     "      <th>Attr56</th>\n",
                     "      <th>Attr57</th>\n",
                     "      <th>Attr58</th>\n",
                     "      <th>Attr59</th>\n",
                     "      <th>Attr60</th>\n",
                     "      <th>Attr61</th>\n",
                     "      <th>Attr62</th>\n",
                     "      <th>Attr63</th>\n",
                     "      <th>Attr64</th>\n",
                     "      <th>class</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0.174190</td>\n",
                     "      <td>0.41299</td>\n",
                     "      <td>0.14371</td>\n",
                     "      <td>1.3480</td>\n",
                     "      <td>-28.9820</td>\n",
                     "      <td>0.60383</td>\n",
                     "      <td>0.219460</td>\n",
                     "      <td>1.1225</td>\n",
                     "      <td>1.1961</td>\n",
                     "      <td>0.46359</td>\n",
                     "      <td>...</td>\n",
                     "      <td>0.163960</td>\n",
                     "      <td>0.375740</td>\n",
                     "      <td>0.83604</td>\n",
                     "      <td>0.000007</td>\n",
                     "      <td>9.7145</td>\n",
                     "      <td>6.2813</td>\n",
                     "      <td>84.291</td>\n",
                     "      <td>4.3303</td>\n",
                     "      <td>4.0341</td>\n",
                     "      <td>b'0'</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>0.146240</td>\n",
                     "      <td>0.46038</td>\n",
                     "      <td>0.28230</td>\n",
                     "      <td>1.6294</td>\n",
                     "      <td>2.5952</td>\n",
                     "      <td>0.00000</td>\n",
                     "      <td>0.171850</td>\n",
                     "      <td>1.1721</td>\n",
                     "      <td>1.6018</td>\n",
                     "      <td>0.53962</td>\n",
                     "      <td>...</td>\n",
                     "      <td>0.027516</td>\n",
                     "      <td>0.271000</td>\n",
                     "      <td>0.90108</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>5.9882</td>\n",
                     "      <td>4.1103</td>\n",
                     "      <td>102.190</td>\n",
                     "      <td>3.5716</td>\n",
                     "      <td>5.9500</td>\n",
                     "      <td>b'0'</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>0.000595</td>\n",
                     "      <td>0.22612</td>\n",
                     "      <td>0.48839</td>\n",
                     "      <td>3.1599</td>\n",
                     "      <td>84.8740</td>\n",
                     "      <td>0.19114</td>\n",
                     "      <td>0.004572</td>\n",
                     "      <td>2.9881</td>\n",
                     "      <td>1.0077</td>\n",
                     "      <td>0.67566</td>\n",
                     "      <td>...</td>\n",
                     "      <td>0.007639</td>\n",
                     "      <td>0.000881</td>\n",
                     "      <td>0.99236</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>6.7742</td>\n",
                     "      <td>3.7922</td>\n",
                     "      <td>64.846</td>\n",
                     "      <td>5.6287</td>\n",
                     "      <td>4.4581</td>\n",
                     "      <td>b'0'</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>0.024526</td>\n",
                     "      <td>0.43236</td>\n",
                     "      <td>0.27546</td>\n",
                     "      <td>1.7833</td>\n",
                     "      <td>-10.1050</td>\n",
                     "      <td>0.56944</td>\n",
                     "      <td>0.024526</td>\n",
                     "      <td>1.3057</td>\n",
                     "      <td>1.0509</td>\n",
                     "      <td>0.56453</td>\n",
                     "      <td>...</td>\n",
                     "      <td>0.048398</td>\n",
                     "      <td>0.043445</td>\n",
                     "      <td>0.95160</td>\n",
                     "      <td>0.142980</td>\n",
                     "      <td>4.2286</td>\n",
                     "      <td>5.0528</td>\n",
                     "      <td>98.783</td>\n",
                     "      <td>3.6950</td>\n",
                     "      <td>3.4844</td>\n",
                     "      <td>b'0'</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0.188290</td>\n",
                     "      <td>0.41504</td>\n",
                     "      <td>0.34231</td>\n",
                     "      <td>1.9279</td>\n",
                     "      <td>-58.2740</td>\n",
                     "      <td>0.00000</td>\n",
                     "      <td>0.233580</td>\n",
                     "      <td>1.4094</td>\n",
                     "      <td>1.3393</td>\n",
                     "      <td>0.58496</td>\n",
                     "      <td>...</td>\n",
                     "      <td>0.176480</td>\n",
                     "      <td>0.321880</td>\n",
                     "      <td>0.82635</td>\n",
                     "      <td>0.073039</td>\n",
                     "      <td>2.5912</td>\n",
                     "      <td>7.0756</td>\n",
                     "      <td>100.540</td>\n",
                     "      <td>3.6303</td>\n",
                     "      <td>4.6375</td>\n",
                     "      <td>b'0'</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>5 rows × 65 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "      Attr1    Attr2    Attr3   Attr4    Attr5    Attr6     Attr7   Attr8  \\\n",
                     "0  0.174190  0.41299  0.14371  1.3480 -28.9820  0.60383  0.219460  1.1225   \n",
                     "1  0.146240  0.46038  0.28230  1.6294   2.5952  0.00000  0.171850  1.1721   \n",
                     "2  0.000595  0.22612  0.48839  3.1599  84.8740  0.19114  0.004572  2.9881   \n",
                     "3  0.024526  0.43236  0.27546  1.7833 -10.1050  0.56944  0.024526  1.3057   \n",
                     "4  0.188290  0.41504  0.34231  1.9279 -58.2740  0.00000  0.233580  1.4094   \n",
                     "\n",
                     "    Attr9   Attr10  ...    Attr56    Attr57   Attr58    Attr59  Attr60  \\\n",
                     "0  1.1961  0.46359  ...  0.163960  0.375740  0.83604  0.000007  9.7145   \n",
                     "1  1.6018  0.53962  ...  0.027516  0.271000  0.90108  0.000000  5.9882   \n",
                     "2  1.0077  0.67566  ...  0.007639  0.000881  0.99236  0.000000  6.7742   \n",
                     "3  1.0509  0.56453  ...  0.048398  0.043445  0.95160  0.142980  4.2286   \n",
                     "4  1.3393  0.58496  ...  0.176480  0.321880  0.82635  0.073039  2.5912   \n",
                     "\n",
                     "   Attr61   Attr62  Attr63  Attr64  class  \n",
                     "0  6.2813   84.291  4.3303  4.0341   b'0'  \n",
                     "1  4.1103  102.190  3.5716  5.9500   b'0'  \n",
                     "2  3.7922   64.846  5.6287  4.4581   b'0'  \n",
                     "3  5.0528   98.783  3.6950  3.4844   b'0'  \n",
                     "4  7.0756  100.540  3.6303  4.6375   b'0'  \n",
                     "\n",
                     "[5 rows x 65 columns]"
                  ]
               },
               "execution_count": 82,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "X.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 83,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Attr1     float64\n",
                     "Attr2     float64\n",
                     "Attr3     float64\n",
                     "Attr4     float64\n",
                     "Attr5     float64\n",
                     "           ...   \n",
                     "Attr61    float64\n",
                     "Attr62    float64\n",
                     "Attr63    float64\n",
                     "Attr64    float64\n",
                     "class      object\n",
                     "Length: 65, dtype: object"
                  ]
               },
               "execution_count": 83,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "X.dtypes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 84,
         "metadata": {
            "pycharm": {
               "name": "#%%\n"
            }
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>Attr1</th>\n",
                     "      <th>Attr2</th>\n",
                     "      <th>Attr3</th>\n",
                     "      <th>Attr4</th>\n",
                     "      <th>Attr5</th>\n",
                     "      <th>Attr6</th>\n",
                     "      <th>Attr7</th>\n",
                     "      <th>Attr8</th>\n",
                     "      <th>Attr9</th>\n",
                     "      <th>Attr10</th>\n",
                     "      <th>...</th>\n",
                     "      <th>Attr55</th>\n",
                     "      <th>Attr56</th>\n",
                     "      <th>Attr57</th>\n",
                     "      <th>Attr58</th>\n",
                     "      <th>Attr59</th>\n",
                     "      <th>Attr60</th>\n",
                     "      <th>Attr61</th>\n",
                     "      <th>Attr62</th>\n",
                     "      <th>Attr63</th>\n",
                     "      <th>Attr64</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>count</th>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>10485.000000</td>\n",
                     "      <td>1.047800e+04</td>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>10489.000000</td>\n",
                     "      <td>10500.000000</td>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>...</td>\n",
                     "      <td>1.050300e+04</td>\n",
                     "      <td>10460.000000</td>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>10474.000000</td>\n",
                     "      <td>10503.000000</td>\n",
                     "      <td>9.911000e+03</td>\n",
                     "      <td>10486.000000</td>\n",
                     "      <td>1.046000e+04</td>\n",
                     "      <td>10485.000000</td>\n",
                     "      <td>10275.000000</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>mean</th>\n",
                     "      <td>0.052844</td>\n",
                     "      <td>0.619911</td>\n",
                     "      <td>0.095490</td>\n",
                     "      <td>9.980499</td>\n",
                     "      <td>-1.347662e+03</td>\n",
                     "      <td>-0.121159</td>\n",
                     "      <td>0.065624</td>\n",
                     "      <td>19.140113</td>\n",
                     "      <td>1.819254</td>\n",
                     "      <td>0.366093</td>\n",
                     "      <td>...</td>\n",
                     "      <td>6.638549e+03</td>\n",
                     "      <td>-0.530082</td>\n",
                     "      <td>-0.014817</td>\n",
                     "      <td>3.848794</td>\n",
                     "      <td>1.429319</td>\n",
                     "      <td>5.713363e+02</td>\n",
                     "      <td>13.935361</td>\n",
                     "      <td>1.355370e+02</td>\n",
                     "      <td>9.095149</td>\n",
                     "      <td>35.766800</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>std</th>\n",
                     "      <td>0.647797</td>\n",
                     "      <td>6.427041</td>\n",
                     "      <td>6.420056</td>\n",
                     "      <td>523.691951</td>\n",
                     "      <td>1.185806e+05</td>\n",
                     "      <td>6.970625</td>\n",
                     "      <td>0.651152</td>\n",
                     "      <td>717.756745</td>\n",
                     "      <td>7.581659</td>\n",
                     "      <td>6.428603</td>\n",
                     "      <td>...</td>\n",
                     "      <td>5.989196e+04</td>\n",
                     "      <td>55.978608</td>\n",
                     "      <td>18.684047</td>\n",
                     "      <td>190.201224</td>\n",
                     "      <td>77.273270</td>\n",
                     "      <td>3.715967e+04</td>\n",
                     "      <td>83.704103</td>\n",
                     "      <td>2.599116e+04</td>\n",
                     "      <td>31.419096</td>\n",
                     "      <td>428.298315</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>min</th>\n",
                     "      <td>-17.692000</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>-479.730000</td>\n",
                     "      <td>0.002080</td>\n",
                     "      <td>-1.190300e+07</td>\n",
                     "      <td>-508.120000</td>\n",
                     "      <td>-17.692000</td>\n",
                     "      <td>-2.081800</td>\n",
                     "      <td>-1.215700</td>\n",
                     "      <td>-479.730000</td>\n",
                     "      <td>...</td>\n",
                     "      <td>-7.513800e+05</td>\n",
                     "      <td>-5691.700000</td>\n",
                     "      <td>-1667.300000</td>\n",
                     "      <td>-198.690000</td>\n",
                     "      <td>-172.070000</td>\n",
                     "      <td>0.000000e+00</td>\n",
                     "      <td>-6.590300</td>\n",
                     "      <td>-2.336500e+06</td>\n",
                     "      <td>-0.000156</td>\n",
                     "      <td>-0.000102</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>25%</th>\n",
                     "      <td>0.000686</td>\n",
                     "      <td>0.253955</td>\n",
                     "      <td>0.017461</td>\n",
                     "      <td>1.040100</td>\n",
                     "      <td>-5.207075e+01</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.002118</td>\n",
                     "      <td>0.431270</td>\n",
                     "      <td>1.011275</td>\n",
                     "      <td>0.297340</td>\n",
                     "      <td>...</td>\n",
                     "      <td>1.462100e+01</td>\n",
                     "      <td>0.005137</td>\n",
                     "      <td>0.006796</td>\n",
                     "      <td>0.875560</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>5.533150e+00</td>\n",
                     "      <td>4.486075</td>\n",
                     "      <td>4.073700e+01</td>\n",
                     "      <td>3.062800</td>\n",
                     "      <td>2.023350</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>50%</th>\n",
                     "      <td>0.043034</td>\n",
                     "      <td>0.464140</td>\n",
                     "      <td>0.198560</td>\n",
                     "      <td>1.605600</td>\n",
                     "      <td>1.579300e+00</td>\n",
                     "      <td>0.000000</td>\n",
                     "      <td>0.050945</td>\n",
                     "      <td>1.111000</td>\n",
                     "      <td>1.199000</td>\n",
                     "      <td>0.515500</td>\n",
                     "      <td>...</td>\n",
                     "      <td>8.822900e+02</td>\n",
                     "      <td>0.051765</td>\n",
                     "      <td>0.106880</td>\n",
                     "      <td>0.953060</td>\n",
                     "      <td>0.002976</td>\n",
                     "      <td>9.952100e+00</td>\n",
                     "      <td>6.677300</td>\n",
                     "      <td>7.066400e+01</td>\n",
                     "      <td>5.139200</td>\n",
                     "      <td>4.059300</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>75%</th>\n",
                     "      <td>0.123805</td>\n",
                     "      <td>0.689330</td>\n",
                     "      <td>0.419545</td>\n",
                     "      <td>2.959500</td>\n",
                     "      <td>5.608400e+01</td>\n",
                     "      <td>0.072584</td>\n",
                     "      <td>0.142275</td>\n",
                     "      <td>2.857100</td>\n",
                     "      <td>2.059100</td>\n",
                     "      <td>0.725635</td>\n",
                     "      <td>...</td>\n",
                     "      <td>4.348900e+03</td>\n",
                     "      <td>0.130010</td>\n",
                     "      <td>0.271310</td>\n",
                     "      <td>0.995927</td>\n",
                     "      <td>0.240320</td>\n",
                     "      <td>2.093600e+01</td>\n",
                     "      <td>10.587500</td>\n",
                     "      <td>1.182200e+02</td>\n",
                     "      <td>8.882600</td>\n",
                     "      <td>9.682750</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>max</th>\n",
                     "      <td>52.652000</td>\n",
                     "      <td>480.730000</td>\n",
                     "      <td>17.708000</td>\n",
                     "      <td>53433.000000</td>\n",
                     "      <td>6.854400e+05</td>\n",
                     "      <td>45.533000</td>\n",
                     "      <td>52.652000</td>\n",
                     "      <td>53432.000000</td>\n",
                     "      <td>740.440000</td>\n",
                     "      <td>11.837000</td>\n",
                     "      <td>...</td>\n",
                     "      <td>3.380500e+06</td>\n",
                     "      <td>293.150000</td>\n",
                     "      <td>552.640000</td>\n",
                     "      <td>18118.000000</td>\n",
                     "      <td>7617.300000</td>\n",
                     "      <td>3.660200e+06</td>\n",
                     "      <td>4470.400000</td>\n",
                     "      <td>1.073500e+06</td>\n",
                     "      <td>1974.500000</td>\n",
                     "      <td>21499.000000</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>8 rows × 64 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "              Attr1         Attr2         Attr3         Attr4         Attr5  \\\n",
                     "count  10503.000000  10503.000000  10503.000000  10485.000000  1.047800e+04   \n",
                     "mean       0.052844      0.619911      0.095490      9.980499 -1.347662e+03   \n",
                     "std        0.647797      6.427041      6.420056    523.691951  1.185806e+05   \n",
                     "min      -17.692000      0.000000   -479.730000      0.002080 -1.190300e+07   \n",
                     "25%        0.000686      0.253955      0.017461      1.040100 -5.207075e+01   \n",
                     "50%        0.043034      0.464140      0.198560      1.605600  1.579300e+00   \n",
                     "75%        0.123805      0.689330      0.419545      2.959500  5.608400e+01   \n",
                     "max       52.652000    480.730000     17.708000  53433.000000  6.854400e+05   \n",
                     "\n",
                     "              Attr6         Attr7         Attr8         Attr9        Attr10  \\\n",
                     "count  10503.000000  10503.000000  10489.000000  10500.000000  10503.000000   \n",
                     "mean      -0.121159      0.065624     19.140113      1.819254      0.366093   \n",
                     "std        6.970625      0.651152    717.756745      7.581659      6.428603   \n",
                     "min     -508.120000    -17.692000     -2.081800     -1.215700   -479.730000   \n",
                     "25%        0.000000      0.002118      0.431270      1.011275      0.297340   \n",
                     "50%        0.000000      0.050945      1.111000      1.199000      0.515500   \n",
                     "75%        0.072584      0.142275      2.857100      2.059100      0.725635   \n",
                     "max       45.533000     52.652000  53432.000000    740.440000     11.837000   \n",
                     "\n",
                     "       ...        Attr55        Attr56        Attr57        Attr58  \\\n",
                     "count  ...  1.050300e+04  10460.000000  10503.000000  10474.000000   \n",
                     "mean   ...  6.638549e+03     -0.530082     -0.014817      3.848794   \n",
                     "std    ...  5.989196e+04     55.978608     18.684047    190.201224   \n",
                     "min    ... -7.513800e+05  -5691.700000  -1667.300000   -198.690000   \n",
                     "25%    ...  1.462100e+01      0.005137      0.006796      0.875560   \n",
                     "50%    ...  8.822900e+02      0.051765      0.106880      0.953060   \n",
                     "75%    ...  4.348900e+03      0.130010      0.271310      0.995927   \n",
                     "max    ...  3.380500e+06    293.150000    552.640000  18118.000000   \n",
                     "\n",
                     "             Attr59        Attr60        Attr61        Attr62        Attr63  \\\n",
                     "count  10503.000000  9.911000e+03  10486.000000  1.046000e+04  10485.000000   \n",
                     "mean       1.429319  5.713363e+02     13.935361  1.355370e+02      9.095149   \n",
                     "std       77.273270  3.715967e+04     83.704103  2.599116e+04     31.419096   \n",
                     "min     -172.070000  0.000000e+00     -6.590300 -2.336500e+06     -0.000156   \n",
                     "25%        0.000000  5.533150e+00      4.486075  4.073700e+01      3.062800   \n",
                     "50%        0.002976  9.952100e+00      6.677300  7.066400e+01      5.139200   \n",
                     "75%        0.240320  2.093600e+01     10.587500  1.182200e+02      8.882600   \n",
                     "max     7617.300000  3.660200e+06   4470.400000  1.073500e+06   1974.500000   \n",
                     "\n",
                     "             Attr64  \n",
                     "count  10275.000000  \n",
                     "mean      35.766800  \n",
                     "std      428.298315  \n",
                     "min       -0.000102  \n",
                     "25%        2.023350  \n",
                     "50%        4.059300  \n",
                     "75%        9.682750  \n",
                     "max    21499.000000  \n",
                     "\n",
                     "[8 rows x 64 columns]"
                  ]
               },
               "execution_count": 84,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "X.describe()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 85,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "['net profit / total assets',\n",
                     " 'total liabilities / total assets',\n",
                     " 'working capital / total assets',\n",
                     " 'current assets / short-term liabilities',\n",
                     " '[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365',\n",
                     " 'retained earnings / total assets',\n",
                     " 'EBIT / total assets',\n",
                     " 'book value of equity / total liabilities',\n",
                     " 'sales / total assets',\n",
                     " 'equity / total assets',\n",
                     " '(gross profit + extraordinary items + financial expenses) / total assets',\n",
                     " 'gross profit / short-term liabilities',\n",
                     " '(gross profit + depreciation) / sales',\n",
                     " '(gross profit + interest) / total assets',\n",
                     " '(total liabilities * 365) / (gross profit + depreciation)',\n",
                     " '(gross profit + depreciation) / total liabilities',\n",
                     " 'total assets / total liabilities',\n",
                     " 'gross profit / total assets',\n",
                     " 'gross profit / sales',\n",
                     " '(inventory * 365) / sales',\n",
                     " 'sales (n) / sales (n-1)',\n",
                     " 'profit on operating activities / total assets',\n",
                     " 'net profit / sales',\n",
                     " 'gross profit (in 3 years) / total assets',\n",
                     " '(equity - share capital) / total assets',\n",
                     " '(net profit + depreciation) / total liabilities',\n",
                     " 'profit on operating activities / financial expenses',\n",
                     " 'working capital / fixed assets',\n",
                     " 'logarithm of total assets',\n",
                     " '(total liabilities - cash) / sales',\n",
                     " '(gross profit + interest) / sales',\n",
                     " '(current liabilities * 365) / cost of products sold',\n",
                     " 'operating expenses / short-term liabilities',\n",
                     " 'operating expenses / total liabilities',\n",
                     " 'profit on sales / total assets',\n",
                     " 'total sales / total assets',\n",
                     " 'constant capital / total assets',\n",
                     " 'profit on sales / sales',\n",
                     " '(current assets - inventory - receivables) / short-term liabilities',\n",
                     " 'total liabilities / ((profit on operating activities + depreciation) * (12/365))',\n",
                     " 'profit on operating activities / sales',\n",
                     " 'rotation receivables + inventory turnover in days',\n",
                     " '(receivables * 365) / sales',\n",
                     " 'net profit / inventory',\n",
                     " '(current assets - inventory) / short-term liabilities',\n",
                     " '(inventory * 365) / cost of products sold',\n",
                     " 'EBITDA (profit on operating activities - depreciation) / total assets',\n",
                     " 'EBITDA (profit on operating activities - depreciation) / sales',\n",
                     " 'current assets / total liabilities',\n",
                     " 'short-term liabilities / total assets',\n",
                     " '(short-term liabilities * 365) / cost of products sold)',\n",
                     " 'equity / fixed assets',\n",
                     " 'constant capital / fixed assets',\n",
                     " 'working capital',\n",
                     " '(sales - cost of products sold) / sales',\n",
                     " '(current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)',\n",
                     " 'total costs / total sales',\n",
                     " 'long-term liabilities / equity',\n",
                     " 'sales / inventory',\n",
                     " 'sales / receivables',\n",
                     " '(short-term liabilities * 365) / sales',\n",
                     " 'sales / short-term liabilities',\n",
                     " 'sales / fixed assets']"
                  ]
               },
               "execution_count": 85,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "feature_names"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "DataFrame zawiera 64 atrybuty numeryczne o zróżnicowanych rozkładach wartości oraz kolumnę `\"class\"` typu `bytes` z klasami 0 i 1. Wiemy, że mamy do czynienia z klasyfikacją binarną - klasa 0 to brak bankructwa, klasa 1 to bankructwo w ciągu najbliższych 3 lat. Przyjrzyjmy się dokładniej naszym danym.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 1 (0.5 punktu)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Wyodrębnij klasy jako osobną zmienną typu `pd.Series`, usuwając je z macierzy `X`. Przekonwertuj go na liczby całkowite.\n",
            "2. Narysuj wykres słupkowy (bar plot) częstotliwości obu klas w całym zbiorze. Upewnij się, że na osi X są numery lub nazwy klas, a oś Y ma wartości w procentach.\n",
            "\n",
            "**Uwaga:** sugerowane jest użycie `if` w podpunkcie 1, żeby można było tę komórkę bezpiecznie odpalić kilka razy.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 86,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [],
         "source": [
            "if \"class\" in X.columns:\n",
            "    y = X.pop(\"class\")\n",
            "y = y.astype(int)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 87,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Text(0, 0.5, 'Częstość')"
                  ]
               },
               "execution_count": 87,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "ax = (y.value_counts() / len(y) * 100).plot(kind='bar')\n",
            "for container in ax.containers:\n",
            "    ax.bar_label(container)\n",
            "\n",
            "plt.title('Procentowy wpływ kazdej klasy')\n",
            "plt.xlabel(\"Klasa\")\n",
            "plt.ylabel(\"Częstość\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 88,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Solution is correct!\n"
               ]
            }
         ],
         "source": [
            "assert \"class\" not in X.columns\n",
            "\n",
            "print(\"Solution is correct!\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Jak widać, klasa pozytywna jest w znacznej mniejszości, stanowi poniżej 5% zbioru. Taki problem nazywamy **klasyfikacją niezbalansowaną (imbalanced classification)**. Mamy tu **klasę dominującą (majority class)** oraz **klasę mniejszościową (minority class)**. Pechowo prawie zawsze interesuje nas ta druga, bo klasa większościowa jest trywialna. Przykładowo, 99% badanych jest zdrowych, a 1% ma niewykryty nowotwór - z oczywistych przyczyn chcemy wykrywać właśnie sytuację rzadką (problem diagnozy jako klasyfikacji jest zasadniczo zawsze niezbalansowany). W dalszej części laboratorium poznamy szereg konsekwencji tego zjawiska i metody na radzenie sobie z nim.\n",
            "\n",
            "Mamy sporo cech, wszystkie numeryczne. Ciekawe, czy mają wartości brakujące, a jeśli tak, to ile. Policzymy to z pomocą biblioteki Pandas i metody `.isna()`. Domyślnie operuje ona na kolumnach, jak większość metod w Pandasie. Sumę wartości per kolumna zwróci nam metoda `.sum()`. Jeżeli podzielimy to przez liczbę wierszy `len(X)`, to otrzymamy ułamek wartości brakujących w każdej kolumnie.\n",
            "\n",
            "Pandas potrafi też stworzyć wykres, z pomocą funkcji np. `.plot.hist()` czy `.plot.bar()`. Przyjmują one opcje formatowania wykresu, z których korzysta pod spodem biblioteka matplotlib.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 89,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<Axes: title={'center': 'Fraction of missing values per column'}>"
                  ]
               },
               "execution_count": 89,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1600x500 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "na_perc = X.isna().sum() / len(X)\n",
            "na_perc.plot.bar(\n",
            "    title=\"Fraction of missing values per column\", figsize=(16, 5))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Jak widać, cecha 37 ma bardzo dużo wartości brakujących, podczas gdy pozostałe cechy mają raczej niewielką ich liczbę. W takiej sytuacji najlepiej usunąć tę cechę, a pozostałe wartości brakujące **uzupełnić / imputować (impute)**. Typowo wykorzystuje się do tego wartość średnią lub medianę z danej kolumny. Ale uwaga - imputacji dokonuje się dopiero po podziale na zbiór treningowy i testowy! W przeciwnym wypadku wykorzystywalibyśmy dane ze zbioru testowego, co sztucznie zawyżyłoby wyniki. Jest to błąd metodologiczny - **wyciek danych (data leakage)**.\n",
            "\n",
            "Podział na zbiór treningowy i testowy to pierwszy moment, kiedy niezbalansowanie danych nam przeszkadza. Jeżeli zrobimy to czysto losowo, to są spore szanse, że w zbiorze testowym będzie tylko klasa negatywna - w końcu jest jej aż >95%. Dlatego wykorzystuje się **próbkowanie ze stratyfikacją (stratified sampling)**, dzięki któremu proporcje klas w zbiorze przed podziałem oraz obu zbiorach po podziale są takie same.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 2 (0.75 punktu)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Usuń kolumnę `\"Attr37\"` ze zbioru danych.\n",
            "2. Dokonaj podziału zbioru na treningowy i testowy w proporcjach 80%-20%, z przemieszaniem (`shuffle`), ze stratyfikacją, wykorzystując funkcję `train_test_split` ze Scikit-learn'a.\n",
            "3. Uzupełnij wartości brakujące średnią wartością cechy z pomocą klasy `SimpleImputer`.\n",
            "\n",
            "**Uwaga:**\n",
            "\n",
            "- jak wcześniej, sugerowane jest użycie `if` w podpunkcie 1\n",
            "- pamiętaj o uwzględnieniu stałego `random_state=0`, aby wyniki były **reprodukowalne (reproducible)**\n",
            "- `stratify` oczekuje wektora klas\n",
            "- wartości do imputacji trzeba wyestymować na zbiorze treningowym (`.fit()`), a potem zastosować te nauczone wartości na obu podzbiorach (treningowym i testowym)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 90,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [],
         "source": [
            "if \"Attr37\" in X:\n",
            "    X.drop(columns=['Attr37'], inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 91,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.compose import ColumnTransformer\n",
            "from sklearn.impute import SimpleImputer\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(\n",
            "    X, y, test_size=.2, shuffle=True, random_state=0, stratify=y)\n",
            "\n",
            "column_transformer = ColumnTransformer([\n",
            "    (\"imputer\", SimpleImputer(strategy=\"mean\"), X.columns)\n",
            "])\n",
            "\n",
            "X_train = column_transformer.fit_transform(X_train)\n",
            "X_test = column_transformer.transform(X_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 92,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Solution is correct!\n"
               ]
            }
         ],
         "source": [
            "import numpy as np\n",
            "\n",
            "assert \"Attr37\" not in X.columns\n",
            "assert not np.any(np.isnan(X_train))\n",
            "assert not np.any(np.isnan(X_test))\n",
            "\n",
            "print(\"Solution is correct!\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "## Prosta klasyfikacja\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Zanim przejdzie się do modeli bardziej złożonych, trzeba najpierw wypróbować coś prostego, żeby mieć punkt odniesienia. Tworzy się dlatego **modele bazowe (baselines)**.\n",
            "\n",
            "W naszym przypadku będzie to **drzewo decyzyjne (decision tree)**. Jest to drzewo binarne z decyzjami if-else, prowadzącymi do klasyfikacji danego przykładu w liściu. Każdy podział w drzewie to pytanie postaci \"Czy wartość cechy X jest większa lub równa Y?\". Trening takiego drzewa to prosty algorytm zachłanny, bardzo przypomina budowę zwykłego drzewa binarnego. W każdym węźle wykonujemy:\n",
            "\n",
            "1. Sprawdź po kolei wszystkie możliwe punkty podziału, czyli każdą (unikalną) wartość każdej cechy, po kolei.\n",
            "2. Dla każdego przypadku podziel zbiór na 2 kawałki: niespełniający warunku (lewe dziecko) i spełniający warunek (prawe dziecko).\n",
            "3. Oblicz jakość podziału według pewnej wybranej funkcji jakości. Im lepiej nasz if/else rozdziela klasy od siebie (im \"czystsze\" są węzły-dzieci), tym wyższa jakość. Innymi słowy, chcemy, żeby do jednego dziecka poszła jedna klasa, a do drugiego druga.\n",
            "4. Wybierz podział o najwyższej jakości.\n",
            "\n",
            "Taki algorytm wykonuje się rekurencyjnie, aż otrzymamy węzeł czysty (pure leaf), czyli taki, w którym są przykłady z tylko jednej klasy. Typowo wykorzystywaną funkcją jakości (kryterium podziału) jest entropia Shannona - im niższa entropia, tym bardziej jednolite są klasy w węźle (czyli wybieramy podział o najniższej entropii).\n",
            "\n",
            "Powyższe wytłumaczenie algorytmu jest oczywiście nieformalne i dość skrótowe. Doskonałe tłumaczenie, z interaktywnymi wizualizacjami, dostępne jest [tutaj](https://mlu-explain.github.io/decision-tree/). W formie filmów - [tutaj](https://www.youtube.com/watch?v=ZVR2Way4nwQ) oraz [tutaj](https://www.youtube.com/watch?v=_L39rN6gz7Y). Dla drzew do regresji - [ten film](https://www.youtube.com/watch?v=g9c66TUylZ4).\n",
            "\n",
            "<img src = https://miro.medium.com/max/1838/1*WyTsLwcAXivFCgNtF0OPqA.png width = \"642\" height = \"451\" >\n",
            "\n",
            "Warto zauważyć, że taka konstrukcja prowadzi zawsze do overfittingu. Otrzymanie liści czystych oznacza, że mamy 100% dokładności na zbiorze treningowym, czyli perfekcyjnie przeuczony klasyfikator. W związku z tym nasze predykcje mają bardzo niski bias, ale bardzo dużą wariancję. Pomimo tego drzewa potrafią dać bardzo przyzwoite wyniki, a w celu ich poprawy można je regularyzować, aby mieć mniej \"rozrośnięte\" drzewo. [Film dla zainteresowanych](https://www.youtube.com/watch?v=D0efHEJsfHo).\n",
            "\n",
            "W tym wypadku AI to naprawdę tylko zbiór if'ów ;)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Mając wytrenowany klasyfikator, trzeba oczywiście sprawdzić, jak dobrze on sobie radzi. Tu natrafiamy na kolejny problem z klasyfikacją niezbalansowaną - zwykła celność (accuracy) na pewno nie zadziała! Typowo wykorzystuje się AUC, nazywane też AUROC (Area Under Receiver Operating Characteristic), bo metryka ta \"widzi\" i uwzględnia niezbalansowanie klas. Wymaga ona przekazania prawdopodobieństwa klasy pozytywnej, a nie tylko binarnej decyzji.\n",
            "\n",
            "Bardzo dobre i bardziej szczegółowe wytłumaczenie, z interktywnymi wizualizacjami, można znaleć [tutaj](https://mlu-explain.github.io/roc-auc/). Dla preferujących filmy - [tutaj](https://www.youtube.com/watch?v=4jRBRDbJemM).\n",
            "\n",
            "Co ważne, z definicji AUROC, trzeba tam użyć prawdopodobieństw klasy pozytywnej (klasy 1). W Scikit-learn'ie zwraca je metoda `.predict_proba()`, która w kolejnych kolumnach zwraca prawdopodobieństwa poszczególnych klas.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 3 (0.75 punktu)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Wytrenuj klasyfikator drzewa decyzyjnego (klasa `DecisionTreeClassifier`). Użyj entropii jako kryterium podziału.\n",
            "2. Oblicz i wypisz AUROC na zbiorze testowym dla drzewa decyzyjnego (funkcja `roc_auc_score`).\n",
            "3. Skomentuj wynik - czy twoim zdaniem osiągnięty AUROC to dużo czy mało, biorąc pod uwagę możliwy zakres wartości tej metryki?\n",
            "\n",
            "**Uwaga:**\n",
            "\n",
            "- pamiętaj o użyciu stałego `random_state=0`\n",
            "- jeżeli drzewo nie wyświetli się samo, użyj `plt.show()` z Matplotliba\n",
            "- pamiętaj o tym, żeby przekazać do metryki AUROC prawdopodobieństwa klasy pozytywnej, a nie binarne predykcje!\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 93,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "np.float64(0.7264402264402264)"
                  ]
               },
               "execution_count": 93,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from sklearn.tree import DecisionTreeClassifier\n",
            "from sklearn.metrics import roc_auc_score\n",
            "\n",
            "tree = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
            "\n",
            "tree.fit(X_train, y_train)\n",
            "\n",
            "y_pred = tree.predict_proba(X_test)[:, 1]\n",
            "auroc = roc_auc_score(y_test, y_pred)\n",
            "\n",
            "auroc"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 94,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Solution is correct!\n"
               ]
            }
         ],
         "source": [
            "assert auroc > 0.7\n",
            "\n",
            "print(\"Solution is correct!\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Metryka AUROC przyjmuje wartości od 0 do 1, gdzie klasyfikator losowy przyjmuje średnio wartość 0.5. Mój klasyfikator przyjął wartość ~0.73 co jest wynikiem średnim i nie jest to najskuteczniejszy model\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "## Uczenie zespołowe, bagging, lasy losowe\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Bardzo często wiele klasyfikatorów działających razem daje lepsze wyniki niż pojedynczy klasyfikator. Takie podejście nazywa się **uczeniem zespołowym (ensemble learning)**. Istnieje wiele różnych podejść do tworzenia takich klasyfikatorów złożonych (ensemble classifiers).\n",
            "\n",
            "Podstawową metodą jest **bagging**:\n",
            "\n",
            "1. Wylosuj N (np. 100, 500, ...) próbek boostrapowych (boostrap sample) ze zbioru treningowego. Próbka boostrapowa to po prostu losowanie ze zwracaniem, gdzie dla wejściowego zbioru z M wierszami losujemy M próbek. Będą tam powtórzenia, średnio nawet 1/3, ale się tym nie przejmujemy.\n",
            "2. Wytrenuj klasyfikator bazowy (base classifier) na każdej z próbek boostrapowych.\n",
            "3. Stwórz klasyfikator złożony poprzez uśrednienie predykcji każdego z klasyfikatorów bazowych.\n",
            "\n",
            "<img src = https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Ensemble_Bagging.svg/440px-Ensemble_Bagging.svg.png width = \"440\" height = \"248\" >\n",
            "\n",
            "Typowo klasyfikatory bazowe są bardzo proste, żeby można było szybko wytrenować ich dużą liczbę. Prawie zawsze używa się do tego drzew decyzyjnych. Dla klasyfikacji uśrednienie wyników polega na głosowaniu - dla nowej próbki każdy klasyfikator bazowy ją klasyfikuje, sumuje się głosy na każdą klasę i zwraca najbardziej popularną decyzję.\n",
            "\n",
            "Taki sposób ensemblingu zmniejsza wariancję klasyfikatora. Intuicyjnie, skoro coś uśredniamy, to siłą rzeczy będzie mniej rozrzucone, bo dużo ciężej będzie osiągnąć jakąś skrajność. Redukuje to też overfitting.\n",
            "\n",
            "**Lasy losowe (Random Forests)** to ulepszenie baggingu. Zaobserwowano, że pomimo losowania próbek boostrapowych, w baggingu poszczególne drzewa są do siebie bardzo podobne (są skorelowane), używają podobnych cech ze zbioru. My natomiast chcemy zróżnicowania, żeby mieć niski bias - redukcją wariancji zajmuje się uśrednianie. Dlatego używa się metody losowej podprzestrzeni (random subspace method) - przy każdym podziale drzewa losuje się tylko pewien podzbiór cech, których możemy użyć do tego podziału. Typowo jest to pierwiastek kwadratowy z ogólnej liczby cech.\n",
            "\n",
            "Zarówno bagging, jak i lasy losowe mają dodatkowo bardzo przyjemną własność - są mało czułe na hiperparametry, szczególnie na liczbę drzew. W praktyce wystarczy ustawić 500 czy 1000 drzew i będzie dobrze działać. Dalsze dostrajanie hiperparametrów może jeszcze trochę poprawić wyniki, ale nie tak bardzo, jak przy innych klasyfikatorach. Jest to zatem doskonały wybór domyślny, kiedy nie wiemy, jakiego klasyfikatora użyć.\n",
            "\n",
            "Dodatkowo jest to problem **embarassingly parallel** - drzewa można trenować w 100% równolegle, dzięki czemu jest to dodatkowo wydajna obliczeniowo metoda.\n",
            "\n",
            "Głębsze wytłumaczenie, z interaktywnymi wizualizacjami, można znaleźć [tutaj](https://mlu-explain.github.io/random-forest/). Dobrze tłumaczy je też [ta seria filmów](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ&t=480s).\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 4 (0.5 punktu)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Wytrenuj klasyfikator Random Forest (klasa `RandomForestClassifier`). Użyj 500 drzew i entropii jako kryterium podziału.\n",
            "2. Sprawdź AUROC na zbiorze testowym.\n",
            "3. Skomentuj wynik w odniesieniu do drzewa decyzyjnego.\n",
            "\n",
            "**Uwaga:** pamiętaj o ustawieniu `random_state=0`. Dla przyspieszenia ustaw `n_jobs=-1` (użyje tylu procesów, ile masz dostępnych rdzeni procesora). Pamiętaj też o przekazaniu prawdopodobieństw do metryki AUROC.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 95,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "np.float64(0.9010635828817647)"
                  ]
               },
               "execution_count": 95,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from sklearn.ensemble import RandomForestClassifier\n",
            "\n",
            "forest = RandomForestClassifier(\n",
            "    n_estimators=500, random_state=0, criterion='entropy', n_jobs=-1)\n",
            "\n",
            "forest.fit(X_train, y_train)\n",
            "\n",
            "y_pred = forest.predict_proba(X_test)[:, 1]\n",
            "auroc = roc_auc_score(y_test, y_pred)\n",
            "\n",
            "auroc"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 96,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Solution is correct!\n"
               ]
            }
         ],
         "source": [
            "assert auroc > 0.85\n",
            "\n",
            "print(\"Solution is correct!\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Wynik jest znacznie lepszy niż dla drzewa decyzyjnego. Róznica jest znaczna bo to az ~25% wzrostu skuteczności.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Jak zobaczymy poniżej, wynik ten możemy jednak jeszcze ulepszyć!\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "## Oversampling, SMOTE\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "W przypadku zbiorów niezbalansowanych można dokonać **balansowania (balancing)** zbioru. Są tutaj 2 metody:\n",
            "\n",
            "- **undersampling**: usunięcie przykładów z klasy dominującej\n",
            "- **oversampling**: wygenerowanie dodatkowych przykładów z klasy mniejszościowej\n",
            "\n",
            "Undersampling działa dobrze, kiedy niezbalansowanie jest niewielkie, a zbiór jest duży (możemy sobie pozwolić na usunięcie jego części). Oversampling typowo daje lepsze wyniki, istnieją dla niego bardzo efektywne algorytmy. W przypadku bardzo dużego niezbalansowania można zrobić oba.\n",
            "\n",
            "Typowym algorytmem oversamplingu jest **SMOTE (Synthetic Minority Oversampling TEchnique)**. Działa on następująco:\n",
            "\n",
            "1. Idź po kolei po przykładach z klasy mniejszościowej\n",
            "2. Znajdź `k` najbliższych przykładów dla próbki, typowo `k=5`\n",
            "3. Wylosuj tylu sąsiadów, ile trzeba do oversamplingu, np. jeżeli chcemy zwiększyć klasę mniejszościową 3 razy (o 200%), to wylosuj 2 z 5 sąsiadów\n",
            "4. Dla każdego z wylosowanych sąsiadów wylosuj punkt na linii prostej między próbką a tym sąsiadem. Dodaj ten punkt jako nową próbkę do zbioru\n",
            "\n",
            "<img src = https://miro.medium.com/max/734/1*yRumRhn89acByodBz0H7oA.png >\n",
            "\n",
            "Taka technika generuje przykłady bardzo podobne do prawdziwych, więc nie zaburza zbioru, a jednocześnie pomaga klasyfikatorom, bo \"zagęszcza\" przestrzeń, w której znajduje się klasa pozytywna.\n",
            "\n",
            "Algorytm SMOTE, jego warianty i inne algorytmy dla problemów niezbalansowanych implementuje biblioteka Imbalanced-learn.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "execution": {
               "iopub.execute_input": "2024-10-07T13:36:43.138444Z",
               "iopub.status.busy": "2024-10-07T13:36:43.137348Z",
               "iopub.status.idle": "2024-10-07T13:36:43.147546Z",
               "shell.execute_reply": "2024-10-07T13:36:43.144776Z",
               "shell.execute_reply.started": "2024-10-07T13:36:43.138374Z"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 5 (1 punkt)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Użyj SMOTE do zbalansowania zbioru treningowego (nie używa się go na zbiorze testowym!) (klasa `SMOTE`). Wytrenuj drzewo decyzyjne oraz las losowy na zbalansowanym zbiorze, użyj tych samych argumentów co wcześniej. Pamiętaj o użyciu wszędzie stałego `random_state=0` oraz przekazaniu prawdopodobieństw do AUROC. Skomentuj wynik.\n",
            "\n",
            "Wartość ROC drzewa decyzyjnego przypisz do zmiennej `tree_roc`, a lasu do `forest_roc`.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 97,
         "metadata": {},
         "outputs": [],
         "source": [
            "# %pip install imblearn"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 98,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<style>#sk-container-id-9 {\n",
                     "  /* Definition of color scheme common for light and dark mode */\n",
                     "  --sklearn-color-text: black;\n",
                     "  --sklearn-color-line: gray;\n",
                     "  /* Definition of color scheme for unfitted estimators */\n",
                     "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                     "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                     "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                     "  --sklearn-color-unfitted-level-3: chocolate;\n",
                     "  /* Definition of color scheme for fitted estimators */\n",
                     "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                     "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                     "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                     "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                     "\n",
                     "  /* Specific color for light theme */\n",
                     "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                     "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                     "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                     "  --sklearn-color-icon: #696969;\n",
                     "\n",
                     "  @media (prefers-color-scheme: dark) {\n",
                     "    /* Redefinition of color scheme for dark theme */\n",
                     "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                     "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                     "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                     "    --sklearn-color-icon: #878787;\n",
                     "  }\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 pre {\n",
                     "  padding: 0;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 input.sk-hidden--visually {\n",
                     "  border: 0;\n",
                     "  clip: rect(1px 1px 1px 1px);\n",
                     "  clip: rect(1px, 1px, 1px, 1px);\n",
                     "  height: 1px;\n",
                     "  margin: -1px;\n",
                     "  overflow: hidden;\n",
                     "  padding: 0;\n",
                     "  position: absolute;\n",
                     "  width: 1px;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-dashed-wrapped {\n",
                     "  border: 1px dashed var(--sklearn-color-line);\n",
                     "  margin: 0 0.4em 0.5em 0.4em;\n",
                     "  box-sizing: border-box;\n",
                     "  padding-bottom: 0.4em;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-container {\n",
                     "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                     "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                     "     so we also need the `!important` here to be able to override the\n",
                     "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                     "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                     "  display: inline-block !important;\n",
                     "  position: relative;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-text-repr-fallback {\n",
                     "  display: none;\n",
                     "}\n",
                     "\n",
                     "div.sk-parallel-item,\n",
                     "div.sk-serial,\n",
                     "div.sk-item {\n",
                     "  /* draw centered vertical line to link estimators */\n",
                     "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                     "  background-size: 2px 100%;\n",
                     "  background-repeat: no-repeat;\n",
                     "  background-position: center center;\n",
                     "}\n",
                     "\n",
                     "/* Parallel-specific style estimator block */\n",
                     "\n",
                     "#sk-container-id-9 div.sk-parallel-item::after {\n",
                     "  content: \"\";\n",
                     "  width: 100%;\n",
                     "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                     "  flex-grow: 1;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-parallel {\n",
                     "  display: flex;\n",
                     "  align-items: stretch;\n",
                     "  justify-content: center;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  position: relative;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-parallel-item {\n",
                     "  display: flex;\n",
                     "  flex-direction: column;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
                     "  align-self: flex-end;\n",
                     "  width: 50%;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
                     "  align-self: flex-start;\n",
                     "  width: 50%;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
                     "  width: 0;\n",
                     "}\n",
                     "\n",
                     "/* Serial-specific style estimator block */\n",
                     "\n",
                     "#sk-container-id-9 div.sk-serial {\n",
                     "  display: flex;\n",
                     "  flex-direction: column;\n",
                     "  align-items: center;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  padding-right: 1em;\n",
                     "  padding-left: 1em;\n",
                     "}\n",
                     "\n",
                     "\n",
                     "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                     "clickable and can be expanded/collapsed.\n",
                     "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                     "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                     "*/\n",
                     "\n",
                     "/* Pipeline and ColumnTransformer style (default) */\n",
                     "\n",
                     "#sk-container-id-9 div.sk-toggleable {\n",
                     "  /* Default theme specific background. It is overwritten whether we have a\n",
                     "  specific estimator or a Pipeline/ColumnTransformer */\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "}\n",
                     "\n",
                     "/* Toggleable label */\n",
                     "#sk-container-id-9 label.sk-toggleable__label {\n",
                     "  cursor: pointer;\n",
                     "  display: block;\n",
                     "  width: 100%;\n",
                     "  margin-bottom: 0;\n",
                     "  padding: 0.5em;\n",
                     "  box-sizing: border-box;\n",
                     "  text-align: center;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
                     "  /* Arrow on the left of the label */\n",
                     "  content: \"▸\";\n",
                     "  float: left;\n",
                     "  margin-right: 0.25em;\n",
                     "  color: var(--sklearn-color-icon);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "}\n",
                     "\n",
                     "/* Toggleable content - dropdown */\n",
                     "\n",
                     "#sk-container-id-9 div.sk-toggleable__content {\n",
                     "  max-height: 0;\n",
                     "  max-width: 0;\n",
                     "  overflow: hidden;\n",
                     "  text-align: left;\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-toggleable__content pre {\n",
                     "  margin: 0.2em;\n",
                     "  border-radius: 0.25em;\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                     "  /* Expand drop-down */\n",
                     "  max-height: 200px;\n",
                     "  max-width: 100%;\n",
                     "  overflow: auto;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                     "  content: \"▾\";\n",
                     "}\n",
                     "\n",
                     "/* Pipeline/ColumnTransformer-specific style */\n",
                     "\n",
                     "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Estimator-specific style */\n",
                     "\n",
                     "/* Colorize estimator box */\n",
                     "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
                     "#sk-container-id-9 div.sk-label label {\n",
                     "  /* The background is the default theme color */\n",
                     "  color: var(--sklearn-color-text-on-default-background);\n",
                     "}\n",
                     "\n",
                     "/* On hover, darken the color of the background */\n",
                     "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Label box, darken color on hover, fitted */\n",
                     "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Estimator label */\n",
                     "\n",
                     "#sk-container-id-9 div.sk-label label {\n",
                     "  font-family: monospace;\n",
                     "  font-weight: bold;\n",
                     "  display: inline-block;\n",
                     "  line-height: 1.2em;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-label-container {\n",
                     "  text-align: center;\n",
                     "}\n",
                     "\n",
                     "/* Estimator-specific */\n",
                     "#sk-container-id-9 div.sk-estimator {\n",
                     "  font-family: monospace;\n",
                     "  border: 1px dotted var(--sklearn-color-border-box);\n",
                     "  border-radius: 0.25em;\n",
                     "  box-sizing: border-box;\n",
                     "  margin-bottom: 0.5em;\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-estimator.fitted {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "/* on hover */\n",
                     "#sk-container-id-9 div.sk-estimator:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                     "\n",
                     "/* Common style for \"i\" and \"?\" */\n",
                     "\n",
                     ".sk-estimator-doc-link,\n",
                     "a:link.sk-estimator-doc-link,\n",
                     "a:visited.sk-estimator-doc-link {\n",
                     "  float: right;\n",
                     "  font-size: smaller;\n",
                     "  line-height: 1em;\n",
                     "  font-family: monospace;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  border-radius: 1em;\n",
                     "  height: 1em;\n",
                     "  width: 1em;\n",
                     "  text-decoration: none !important;\n",
                     "  margin-left: 1ex;\n",
                     "  /* unfitted */\n",
                     "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-unfitted-level-1);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link.fitted,\n",
                     "a:link.sk-estimator-doc-link.fitted,\n",
                     "a:visited.sk-estimator-doc-link.fitted {\n",
                     "  /* fitted */\n",
                     "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-fitted-level-1);\n",
                     "}\n",
                     "\n",
                     "/* On hover */\n",
                     "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                     ".sk-estimator-doc-link:hover,\n",
                     "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                     ".sk-estimator-doc-link:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                     ".sk-estimator-doc-link.fitted:hover,\n",
                     "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                     ".sk-estimator-doc-link.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "/* Span, style for the box shown on hovering the info icon */\n",
                     ".sk-estimator-doc-link span {\n",
                     "  display: none;\n",
                     "  z-index: 9999;\n",
                     "  position: relative;\n",
                     "  font-weight: normal;\n",
                     "  right: .2ex;\n",
                     "  padding: .5ex;\n",
                     "  margin: .5ex;\n",
                     "  width: min-content;\n",
                     "  min-width: 20ex;\n",
                     "  max-width: 50ex;\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  box-shadow: 2pt 2pt 4pt #999;\n",
                     "  /* unfitted */\n",
                     "  background: var(--sklearn-color-unfitted-level-0);\n",
                     "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link.fitted span {\n",
                     "  /* fitted */\n",
                     "  background: var(--sklearn-color-fitted-level-0);\n",
                     "  border: var(--sklearn-color-fitted-level-3);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link:hover span {\n",
                     "  display: block;\n",
                     "}\n",
                     "\n",
                     "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                     "\n",
                     "#sk-container-id-9 a.estimator_doc_link {\n",
                     "  float: right;\n",
                     "  font-size: 1rem;\n",
                     "  line-height: 1em;\n",
                     "  font-family: monospace;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  border-radius: 1rem;\n",
                     "  height: 1rem;\n",
                     "  width: 1rem;\n",
                     "  text-decoration: none;\n",
                     "  /* unfitted */\n",
                     "  color: var(--sklearn-color-unfitted-level-1);\n",
                     "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
                     "  /* fitted */\n",
                     "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-fitted-level-1);\n",
                     "}\n",
                     "\n",
                     "/* On hover */\n",
                     "#sk-container-id-9 a.estimator_doc_link:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-3);\n",
                     "}\n",
                     "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=500, n_jobs=-1,\n",
                     "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=500, n_jobs=-1,\n",
                     "                       random_state=0)</pre></div> </div></div></div></div>"
                  ],
                  "text/plain": [
                     "RandomForestClassifier(criterion='entropy', n_estimators=500, n_jobs=-1,\n",
                     "                       random_state=0)"
                  ]
               },
               "execution_count": 98,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from imblearn.over_sampling import SMOTE\n",
            "\n",
            "sm = SMOTE(random_state=0)\n",
            "X_train_balanced, y_train_balanced = sm.fit_resample(X_train, y_train)\n",
            "\n",
            "tree = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
            "forest = RandomForestClassifier(\n",
            "    criterion='entropy', random_state=0, n_estimators=500, n_jobs=-1)\n",
            "\n",
            "tree.fit(X_train_balanced, y_train_balanced)\n",
            "forest.fit(X_train_balanced, y_train_balanced)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 99,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(np.float64(0.70995670995671), np.float64(0.9041539268811997))"
                  ]
               },
               "execution_count": 99,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "y_pred_tree = tree.predict_proba(X_test)[:, 1]\n",
            "y_pred_forest = forest.predict_proba(X_test)[:, 1]\n",
            "\n",
            "tree_roc = roc_auc_score(y_test, y_pred_tree)\n",
            "forest_roc = roc_auc_score(y_test, y_pred_forest)\n",
            "\n",
            "tree_roc, forest_roc"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 100,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [],
         "source": [
            "assert 0.6 < tree_roc < 0.8\n",
            "assert 0.8 < forest_roc < 0.95"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "W obu przypadkach wynik jest lepszy niż bez oversamplingu, aczkolwiek nieznacznie.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "W dalszej części laboratorium używaj zbioru po zastosowaniu SMOTE do treningu klasyfikatorów.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "## Dostrajanie (tuning) hiperparametrów\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Lasy losowe są stosunkowo mało czułe na dobór hiperparametrów - i dobrze, bo mają ich dość dużo. Można zawsze jednak spróbować to zrobić, a w szczególności najważniejszy jest parametr `max_features`, oznaczający, ile cech losować przy każdym podziale drzewa. Typowo sprawdza się wartości z zakresu `[0.1, 0.5]`.\n",
            "\n",
            "W kwestii szybkości, kiedy dostrajamy hiperparametry, to mniej oczywiste jest, jakiego `n_jobs` użyć. Z jednej strony klasyfikator może być trenowany na wielu procesach, a z drugiej można trenować wiele klasyfikatorów na różnych zestawach hiperparametrów równolegle. Jeżeli nasz klasyfikator bardzo dobrze się uwspółbieżnia (jak Random Forest), to można dać mu nawet wszystkie rdzenie, a za to wypróbowywać kolejne zestawy hiperparametrów sekwencyjnie. Warto ustawić parametr `verbose` na 2 lub więcej, żeby dostać logi podczas długiego treningu i mierzyć czas wykonania. W praktyce ustawia się to metodą prób i błędów.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 6 (1 punkt)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Dobierz wartość hiperparametru `max_features`:\n",
            "   - użyj grid search z 5 foldami\n",
            "   - wypróbuj wartości `[0.1, 0.2, 0.3, 0.4, 0.5]`\n",
            "   - wybierz model o najwyższym AUROC (argument `scoring`)\n",
            "2. Sprawdź, jaka była optymalna wartość `max_features`. Jest to atrybut wytrenowanego `GridSearchCV`.\n",
            "3. Skomentuj wynik. Czy warto było poświęcić czas i zasoby na tę procedurę?\n",
            "4. Wynik przypisz do zmiennej `auroc`.\n",
            "\n",
            "**Uwaga:**\n",
            "\n",
            "- pamiętaj, żeby jako estymatora przekazanego do grid search'a użyć instancji Random Forest, która ma już ustawione `random_state=0` i `n_jobs`\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 101,
         "metadata": {
            "editable": true,
            "pycharm": {
               "is_executing": true,
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<style>#sk-container-id-10 {\n",
                     "  /* Definition of color scheme common for light and dark mode */\n",
                     "  --sklearn-color-text: black;\n",
                     "  --sklearn-color-line: gray;\n",
                     "  /* Definition of color scheme for unfitted estimators */\n",
                     "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                     "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                     "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                     "  --sklearn-color-unfitted-level-3: chocolate;\n",
                     "  /* Definition of color scheme for fitted estimators */\n",
                     "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                     "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                     "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                     "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                     "\n",
                     "  /* Specific color for light theme */\n",
                     "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                     "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                     "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                     "  --sklearn-color-icon: #696969;\n",
                     "\n",
                     "  @media (prefers-color-scheme: dark) {\n",
                     "    /* Redefinition of color scheme for dark theme */\n",
                     "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                     "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                     "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                     "    --sklearn-color-icon: #878787;\n",
                     "  }\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 pre {\n",
                     "  padding: 0;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 input.sk-hidden--visually {\n",
                     "  border: 0;\n",
                     "  clip: rect(1px 1px 1px 1px);\n",
                     "  clip: rect(1px, 1px, 1px, 1px);\n",
                     "  height: 1px;\n",
                     "  margin: -1px;\n",
                     "  overflow: hidden;\n",
                     "  padding: 0;\n",
                     "  position: absolute;\n",
                     "  width: 1px;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-dashed-wrapped {\n",
                     "  border: 1px dashed var(--sklearn-color-line);\n",
                     "  margin: 0 0.4em 0.5em 0.4em;\n",
                     "  box-sizing: border-box;\n",
                     "  padding-bottom: 0.4em;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-container {\n",
                     "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                     "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                     "     so we also need the `!important` here to be able to override the\n",
                     "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                     "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                     "  display: inline-block !important;\n",
                     "  position: relative;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-text-repr-fallback {\n",
                     "  display: none;\n",
                     "}\n",
                     "\n",
                     "div.sk-parallel-item,\n",
                     "div.sk-serial,\n",
                     "div.sk-item {\n",
                     "  /* draw centered vertical line to link estimators */\n",
                     "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                     "  background-size: 2px 100%;\n",
                     "  background-repeat: no-repeat;\n",
                     "  background-position: center center;\n",
                     "}\n",
                     "\n",
                     "/* Parallel-specific style estimator block */\n",
                     "\n",
                     "#sk-container-id-10 div.sk-parallel-item::after {\n",
                     "  content: \"\";\n",
                     "  width: 100%;\n",
                     "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                     "  flex-grow: 1;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-parallel {\n",
                     "  display: flex;\n",
                     "  align-items: stretch;\n",
                     "  justify-content: center;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  position: relative;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-parallel-item {\n",
                     "  display: flex;\n",
                     "  flex-direction: column;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
                     "  align-self: flex-end;\n",
                     "  width: 50%;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
                     "  align-self: flex-start;\n",
                     "  width: 50%;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
                     "  width: 0;\n",
                     "}\n",
                     "\n",
                     "/* Serial-specific style estimator block */\n",
                     "\n",
                     "#sk-container-id-10 div.sk-serial {\n",
                     "  display: flex;\n",
                     "  flex-direction: column;\n",
                     "  align-items: center;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  padding-right: 1em;\n",
                     "  padding-left: 1em;\n",
                     "}\n",
                     "\n",
                     "\n",
                     "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                     "clickable and can be expanded/collapsed.\n",
                     "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                     "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                     "*/\n",
                     "\n",
                     "/* Pipeline and ColumnTransformer style (default) */\n",
                     "\n",
                     "#sk-container-id-10 div.sk-toggleable {\n",
                     "  /* Default theme specific background. It is overwritten whether we have a\n",
                     "  specific estimator or a Pipeline/ColumnTransformer */\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "}\n",
                     "\n",
                     "/* Toggleable label */\n",
                     "#sk-container-id-10 label.sk-toggleable__label {\n",
                     "  cursor: pointer;\n",
                     "  display: block;\n",
                     "  width: 100%;\n",
                     "  margin-bottom: 0;\n",
                     "  padding: 0.5em;\n",
                     "  box-sizing: border-box;\n",
                     "  text-align: center;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
                     "  /* Arrow on the left of the label */\n",
                     "  content: \"▸\";\n",
                     "  float: left;\n",
                     "  margin-right: 0.25em;\n",
                     "  color: var(--sklearn-color-icon);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "}\n",
                     "\n",
                     "/* Toggleable content - dropdown */\n",
                     "\n",
                     "#sk-container-id-10 div.sk-toggleable__content {\n",
                     "  max-height: 0;\n",
                     "  max-width: 0;\n",
                     "  overflow: hidden;\n",
                     "  text-align: left;\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-toggleable__content pre {\n",
                     "  margin: 0.2em;\n",
                     "  border-radius: 0.25em;\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                     "  /* Expand drop-down */\n",
                     "  max-height: 200px;\n",
                     "  max-width: 100%;\n",
                     "  overflow: auto;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                     "  content: \"▾\";\n",
                     "}\n",
                     "\n",
                     "/* Pipeline/ColumnTransformer-specific style */\n",
                     "\n",
                     "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Estimator-specific style */\n",
                     "\n",
                     "/* Colorize estimator box */\n",
                     "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
                     "#sk-container-id-10 div.sk-label label {\n",
                     "  /* The background is the default theme color */\n",
                     "  color: var(--sklearn-color-text-on-default-background);\n",
                     "}\n",
                     "\n",
                     "/* On hover, darken the color of the background */\n",
                     "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Label box, darken color on hover, fitted */\n",
                     "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Estimator label */\n",
                     "\n",
                     "#sk-container-id-10 div.sk-label label {\n",
                     "  font-family: monospace;\n",
                     "  font-weight: bold;\n",
                     "  display: inline-block;\n",
                     "  line-height: 1.2em;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-label-container {\n",
                     "  text-align: center;\n",
                     "}\n",
                     "\n",
                     "/* Estimator-specific */\n",
                     "#sk-container-id-10 div.sk-estimator {\n",
                     "  font-family: monospace;\n",
                     "  border: 1px dotted var(--sklearn-color-border-box);\n",
                     "  border-radius: 0.25em;\n",
                     "  box-sizing: border-box;\n",
                     "  margin-bottom: 0.5em;\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-estimator.fitted {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "/* on hover */\n",
                     "#sk-container-id-10 div.sk-estimator:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                     "\n",
                     "/* Common style for \"i\" and \"?\" */\n",
                     "\n",
                     ".sk-estimator-doc-link,\n",
                     "a:link.sk-estimator-doc-link,\n",
                     "a:visited.sk-estimator-doc-link {\n",
                     "  float: right;\n",
                     "  font-size: smaller;\n",
                     "  line-height: 1em;\n",
                     "  font-family: monospace;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  border-radius: 1em;\n",
                     "  height: 1em;\n",
                     "  width: 1em;\n",
                     "  text-decoration: none !important;\n",
                     "  margin-left: 1ex;\n",
                     "  /* unfitted */\n",
                     "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-unfitted-level-1);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link.fitted,\n",
                     "a:link.sk-estimator-doc-link.fitted,\n",
                     "a:visited.sk-estimator-doc-link.fitted {\n",
                     "  /* fitted */\n",
                     "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-fitted-level-1);\n",
                     "}\n",
                     "\n",
                     "/* On hover */\n",
                     "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                     ".sk-estimator-doc-link:hover,\n",
                     "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                     ".sk-estimator-doc-link:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                     ".sk-estimator-doc-link.fitted:hover,\n",
                     "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                     ".sk-estimator-doc-link.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "/* Span, style for the box shown on hovering the info icon */\n",
                     ".sk-estimator-doc-link span {\n",
                     "  display: none;\n",
                     "  z-index: 9999;\n",
                     "  position: relative;\n",
                     "  font-weight: normal;\n",
                     "  right: .2ex;\n",
                     "  padding: .5ex;\n",
                     "  margin: .5ex;\n",
                     "  width: min-content;\n",
                     "  min-width: 20ex;\n",
                     "  max-width: 50ex;\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  box-shadow: 2pt 2pt 4pt #999;\n",
                     "  /* unfitted */\n",
                     "  background: var(--sklearn-color-unfitted-level-0);\n",
                     "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link.fitted span {\n",
                     "  /* fitted */\n",
                     "  background: var(--sklearn-color-fitted-level-0);\n",
                     "  border: var(--sklearn-color-fitted-level-3);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link:hover span {\n",
                     "  display: block;\n",
                     "}\n",
                     "\n",
                     "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                     "\n",
                     "#sk-container-id-10 a.estimator_doc_link {\n",
                     "  float: right;\n",
                     "  font-size: 1rem;\n",
                     "  line-height: 1em;\n",
                     "  font-family: monospace;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  border-radius: 1rem;\n",
                     "  height: 1rem;\n",
                     "  width: 1rem;\n",
                     "  text-decoration: none;\n",
                     "  /* unfitted */\n",
                     "  color: var(--sklearn-color-unfitted-level-1);\n",
                     "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
                     "  /* fitted */\n",
                     "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-fitted-level-1);\n",
                     "}\n",
                     "\n",
                     "/* On hover */\n",
                     "#sk-container-id-10 a.estimator_doc_link:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-3);\n",
                     "}\n",
                     "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
                     "             estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
                     "                                              n_estimators=500, n_jobs=-1,\n",
                     "                                              random_state=0),\n",
                     "             n_jobs=-1, param_grid={&#x27;max_features&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5]},\n",
                     "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
                     "             estimator=RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
                     "                                              n_estimators=500, n_jobs=-1,\n",
                     "                                              random_state=0),\n",
                     "             n_jobs=-1, param_grid={&#x27;max_features&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5]},\n",
                     "             scoring=&#x27;roc_auc&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=0.2, n_estimators=500,\n",
                     "                       n_jobs=-1, random_state=0)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=0.2, n_estimators=500,\n",
                     "                       n_jobs=-1, random_state=0)</pre></div> </div></div></div></div></div></div></div></div></div>"
                  ],
                  "text/plain": [
                     "GridSearchCV(cv=5,\n",
                     "             estimator=RandomForestClassifier(criterion='entropy',\n",
                     "                                              n_estimators=500, n_jobs=-1,\n",
                     "                                              random_state=0),\n",
                     "             n_jobs=-1, param_grid={'max_features': [0.1, 0.2, 0.3, 0.4, 0.5]},\n",
                     "             scoring='roc_auc')"
                  ]
               },
               "execution_count": 101,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from sklearn.model_selection import GridSearchCV\n",
            "\n",
            "forest = RandomForestClassifier(\n",
            "    criterion='entropy', random_state=0, n_estimators=500, n_jobs=-1)\n",
            "\n",
            "param_grid = {\n",
            "    \"max_features\": [0.1, 0.2, 0.3, 0.4, 0.5]\n",
            "}\n",
            "\n",
            "gs = GridSearchCV(forest, param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
            "\n",
            "gs.fit(X_train_balanced, y_train_balanced)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 102,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'max_features': 0.2}\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "np.float64(0.9117296844569572)"
                  ]
               },
               "execution_count": 102,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# results\n",
            "\n",
            "print(gs.best_params_)\n",
            "\n",
            "y_pred = gs.predict_proba(X_test)[:, 1]\n",
            "auroc = roc_auc_score(y_test, y_pred)\n",
            "\n",
            "auroc"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 103,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Solution is correct!\n"
               ]
            }
         ],
         "source": [
            "assert 0.9 <= auroc <= 0.95\n",
            "\n",
            "print(\"Solution is correct!\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Zastosowanie tuningu hiperparametrów jeszcze bardziej poprawiło wynik. Model jest teraz jeszcze bardziej skuteczny. Wzrost skuteczności jest niewielki, więc prawdopodobnie nie było duzej potrzeby na tuning tego modelu, ale dla celów edukacyjnych warto było to zrobić.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "W praktycznych zastosowaniach data scientist wedle własnego uznana, doświadczenia, dostępnego czasu i zasobów wybiera, czy dostrajać hiperparametry i w jak szerokim zakresie. Dla Random Forest na szczęście często może nie być znaczącej potrzeby, i za to go lubimy :)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "**Random Forest - podsumowanie**\n",
            "\n",
            "1. Model oparty o uczenie zespołowe\n",
            "2. Kluczowe elementy:\n",
            "   - bagging: uczenie wielu klasyfikatorów na próbkach boostrapowych\n",
            "   - metoda losowej podprzestrzeni: losujemy podzbiór cech do każdego podziału drzewa\n",
            "   - uśredniamy głosy klasyfikatorów\n",
            "3. Dość odporny na overfitting, zmniejsza wariancję błędu dzięki uśrednianiu\n",
            "4. Mało czuły na hiperparametry\n",
            "5. Przeciętnie bardzo dobre wyniki, doskonały wybór domyślny przy wybieraniu algorytmu klasyfikacji\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "## Boosting\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Drugą bardzo ważną grupą algorytmów ensemblingu jest **boosting**, też oparty o drzewa decyzyjne. O ile Random Forest trenował wszystkie klasyfikatory bazowe równolegle i je uśredniał, o tyle boosting robi to sekwencyjnie. Drzewa te uczą się na całym zbiorze, nie na próbkach boostrapowych. Idea jest następująca: trenujemy drzewo decyzyjne, radzi sobie przeciętnie i popełnia błędy na częsci przykładów treningowych. Dokładamy kolejne, ale znające błędy swojego poprzednika, dzięki czemu może to uwzględnić i je poprawić. W związku z tym \"boostuje\" się dzięki wiedzy od poprzednika. Dokładamy kolejne drzewa zgodnie z tą samą zasadą.\n",
            "\n",
            "Jak uczyć się na błędach poprzednika? Jest to pewna **funkcja kosztu** (błędu), którą chcemy zminimalizować. Zakłada się jakąś jej konkretną postać, np. squared error dla regresji, albo logistic loss dla klasyfikacji. Później wykorzystuje się spadek wzdłuż gradientu (gradient descent), aby nauczyć się, w jakim kierunku powinny optymalizować kolejne drzewa, żeby zminimalizować błędy poprzednika. Jest to konkretnie **gradient boosting**, absolutnie najpopularniejsza forma boostingu, i jeden z najpopularniejszych i osiągających najlepsze wyniki algorytmów ML.\n",
            "\n",
            "Tyle co do intuicji. Ogólny algorytm gradient boostingu jest trochę bardziej skomplikowany. Bardzo dobrze i krok po kroku tłumaczy go [ta seria filmów na YT](https://www.youtube.com/watch?v=3CC4N4z3GJc). Szczególnie ważne implementacje gradient boostingu to **XGBoost (Extreme Gradient Boosting)** oraz **LightGBM (Light Gradient Boosting Machine)**. XGBoost był prawdziwym przełomem w ML, uzyskując doskonałe wyniki i bardzo dobrze się skalując - był wykorzystany w CERNie do wykrywania cząstki Higgsa w zbiorze z pomiarów LHC mającym 10 milionów próbek. Jego implementacja jest dość złożona, ale dobrze tłumaczy ją [inna seria filmików na YT](https://www.youtube.com/watch?v=OtD8wVaFm6E).\n",
            "\n",
            "![](xgboost.png)\n",
            "\n",
            "Obecnie najczęściej wykorzystuje się LightGBM. Został stworzony przez Microsoft na podstawie doświadczeń z XGBoostem. Został jeszcze bardziej ulepszony i przyspieszony, ale różnice są głównie implementacyjne. Różnice dobrze tłumaczy [ta prezentacja z konferencji PyData](https://www.youtube.com/watch?v=5CWwwtEM2TA) oraz [prezentacja Microsoftu](https://www.youtube.com/watch?v=5nKSMXBFhes). Dla zainteresowanych - [praktyczne aspekty LightGBM](https://www.kaggle.com/code/prashant111/lightgbm-classifier-in-python/notebook).\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 7 (0.5 punktu)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Wytrenuj klasyfikator LightGBM (klasa `LGBMClassifier`). Przekaż `importance_type=\"gain\"` - przyda nam się to za chwilę.\n",
            "2. Sprawdź AUROC na zbiorze testowym.\n",
            "3. Skomentuj wynik w odniesieniu do wcześniejszych algorytmów.\n",
            "\n",
            "Pamiętaj o `random_state`, `n_jobs` i prawdopodobieństwach dla AUROC.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 104,
         "metadata": {},
         "outputs": [],
         "source": [
            "# %pip install lightgbm\n",
            "# %brew install libomp"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 105,
         "metadata": {
            "editable": true,
            "pycharm": {
               "is_executing": true,
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[LightGBM] [Info] Number of positive: 8006, number of negative: 8006\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 16012, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<style>#sk-container-id-11 {\n",
                     "  /* Definition of color scheme common for light and dark mode */\n",
                     "  --sklearn-color-text: black;\n",
                     "  --sklearn-color-line: gray;\n",
                     "  /* Definition of color scheme for unfitted estimators */\n",
                     "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                     "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                     "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                     "  --sklearn-color-unfitted-level-3: chocolate;\n",
                     "  /* Definition of color scheme for fitted estimators */\n",
                     "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                     "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                     "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                     "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                     "\n",
                     "  /* Specific color for light theme */\n",
                     "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                     "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                     "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                     "  --sklearn-color-icon: #696969;\n",
                     "\n",
                     "  @media (prefers-color-scheme: dark) {\n",
                     "    /* Redefinition of color scheme for dark theme */\n",
                     "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                     "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                     "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                     "    --sklearn-color-icon: #878787;\n",
                     "  }\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 pre {\n",
                     "  padding: 0;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 input.sk-hidden--visually {\n",
                     "  border: 0;\n",
                     "  clip: rect(1px 1px 1px 1px);\n",
                     "  clip: rect(1px, 1px, 1px, 1px);\n",
                     "  height: 1px;\n",
                     "  margin: -1px;\n",
                     "  overflow: hidden;\n",
                     "  padding: 0;\n",
                     "  position: absolute;\n",
                     "  width: 1px;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-dashed-wrapped {\n",
                     "  border: 1px dashed var(--sklearn-color-line);\n",
                     "  margin: 0 0.4em 0.5em 0.4em;\n",
                     "  box-sizing: border-box;\n",
                     "  padding-bottom: 0.4em;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-container {\n",
                     "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                     "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                     "     so we also need the `!important` here to be able to override the\n",
                     "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                     "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                     "  display: inline-block !important;\n",
                     "  position: relative;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-text-repr-fallback {\n",
                     "  display: none;\n",
                     "}\n",
                     "\n",
                     "div.sk-parallel-item,\n",
                     "div.sk-serial,\n",
                     "div.sk-item {\n",
                     "  /* draw centered vertical line to link estimators */\n",
                     "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                     "  background-size: 2px 100%;\n",
                     "  background-repeat: no-repeat;\n",
                     "  background-position: center center;\n",
                     "}\n",
                     "\n",
                     "/* Parallel-specific style estimator block */\n",
                     "\n",
                     "#sk-container-id-11 div.sk-parallel-item::after {\n",
                     "  content: \"\";\n",
                     "  width: 100%;\n",
                     "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                     "  flex-grow: 1;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-parallel {\n",
                     "  display: flex;\n",
                     "  align-items: stretch;\n",
                     "  justify-content: center;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  position: relative;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-parallel-item {\n",
                     "  display: flex;\n",
                     "  flex-direction: column;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
                     "  align-self: flex-end;\n",
                     "  width: 50%;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
                     "  align-self: flex-start;\n",
                     "  width: 50%;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
                     "  width: 0;\n",
                     "}\n",
                     "\n",
                     "/* Serial-specific style estimator block */\n",
                     "\n",
                     "#sk-container-id-11 div.sk-serial {\n",
                     "  display: flex;\n",
                     "  flex-direction: column;\n",
                     "  align-items: center;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  padding-right: 1em;\n",
                     "  padding-left: 1em;\n",
                     "}\n",
                     "\n",
                     "\n",
                     "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                     "clickable and can be expanded/collapsed.\n",
                     "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                     "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                     "*/\n",
                     "\n",
                     "/* Pipeline and ColumnTransformer style (default) */\n",
                     "\n",
                     "#sk-container-id-11 div.sk-toggleable {\n",
                     "  /* Default theme specific background. It is overwritten whether we have a\n",
                     "  specific estimator or a Pipeline/ColumnTransformer */\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "}\n",
                     "\n",
                     "/* Toggleable label */\n",
                     "#sk-container-id-11 label.sk-toggleable__label {\n",
                     "  cursor: pointer;\n",
                     "  display: block;\n",
                     "  width: 100%;\n",
                     "  margin-bottom: 0;\n",
                     "  padding: 0.5em;\n",
                     "  box-sizing: border-box;\n",
                     "  text-align: center;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
                     "  /* Arrow on the left of the label */\n",
                     "  content: \"▸\";\n",
                     "  float: left;\n",
                     "  margin-right: 0.25em;\n",
                     "  color: var(--sklearn-color-icon);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "}\n",
                     "\n",
                     "/* Toggleable content - dropdown */\n",
                     "\n",
                     "#sk-container-id-11 div.sk-toggleable__content {\n",
                     "  max-height: 0;\n",
                     "  max-width: 0;\n",
                     "  overflow: hidden;\n",
                     "  text-align: left;\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-toggleable__content pre {\n",
                     "  margin: 0.2em;\n",
                     "  border-radius: 0.25em;\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                     "  /* Expand drop-down */\n",
                     "  max-height: 200px;\n",
                     "  max-width: 100%;\n",
                     "  overflow: auto;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                     "  content: \"▾\";\n",
                     "}\n",
                     "\n",
                     "/* Pipeline/ColumnTransformer-specific style */\n",
                     "\n",
                     "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Estimator-specific style */\n",
                     "\n",
                     "/* Colorize estimator box */\n",
                     "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
                     "#sk-container-id-11 div.sk-label label {\n",
                     "  /* The background is the default theme color */\n",
                     "  color: var(--sklearn-color-text-on-default-background);\n",
                     "}\n",
                     "\n",
                     "/* On hover, darken the color of the background */\n",
                     "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Label box, darken color on hover, fitted */\n",
                     "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Estimator label */\n",
                     "\n",
                     "#sk-container-id-11 div.sk-label label {\n",
                     "  font-family: monospace;\n",
                     "  font-weight: bold;\n",
                     "  display: inline-block;\n",
                     "  line-height: 1.2em;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-label-container {\n",
                     "  text-align: center;\n",
                     "}\n",
                     "\n",
                     "/* Estimator-specific */\n",
                     "#sk-container-id-11 div.sk-estimator {\n",
                     "  font-family: monospace;\n",
                     "  border: 1px dotted var(--sklearn-color-border-box);\n",
                     "  border-radius: 0.25em;\n",
                     "  box-sizing: border-box;\n",
                     "  margin-bottom: 0.5em;\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-estimator.fitted {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-0);\n",
                     "}\n",
                     "\n",
                     "/* on hover */\n",
                     "#sk-container-id-11 div.sk-estimator:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-2);\n",
                     "}\n",
                     "\n",
                     "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                     "\n",
                     "/* Common style for \"i\" and \"?\" */\n",
                     "\n",
                     ".sk-estimator-doc-link,\n",
                     "a:link.sk-estimator-doc-link,\n",
                     "a:visited.sk-estimator-doc-link {\n",
                     "  float: right;\n",
                     "  font-size: smaller;\n",
                     "  line-height: 1em;\n",
                     "  font-family: monospace;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  border-radius: 1em;\n",
                     "  height: 1em;\n",
                     "  width: 1em;\n",
                     "  text-decoration: none !important;\n",
                     "  margin-left: 1ex;\n",
                     "  /* unfitted */\n",
                     "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-unfitted-level-1);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link.fitted,\n",
                     "a:link.sk-estimator-doc-link.fitted,\n",
                     "a:visited.sk-estimator-doc-link.fitted {\n",
                     "  /* fitted */\n",
                     "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-fitted-level-1);\n",
                     "}\n",
                     "\n",
                     "/* On hover */\n",
                     "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                     ".sk-estimator-doc-link:hover,\n",
                     "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                     ".sk-estimator-doc-link:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                     ".sk-estimator-doc-link.fitted:hover,\n",
                     "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                     ".sk-estimator-doc-link.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "/* Span, style for the box shown on hovering the info icon */\n",
                     ".sk-estimator-doc-link span {\n",
                     "  display: none;\n",
                     "  z-index: 9999;\n",
                     "  position: relative;\n",
                     "  font-weight: normal;\n",
                     "  right: .2ex;\n",
                     "  padding: .5ex;\n",
                     "  margin: .5ex;\n",
                     "  width: min-content;\n",
                     "  min-width: 20ex;\n",
                     "  max-width: 50ex;\n",
                     "  color: var(--sklearn-color-text);\n",
                     "  box-shadow: 2pt 2pt 4pt #999;\n",
                     "  /* unfitted */\n",
                     "  background: var(--sklearn-color-unfitted-level-0);\n",
                     "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link.fitted span {\n",
                     "  /* fitted */\n",
                     "  background: var(--sklearn-color-fitted-level-0);\n",
                     "  border: var(--sklearn-color-fitted-level-3);\n",
                     "}\n",
                     "\n",
                     ".sk-estimator-doc-link:hover span {\n",
                     "  display: block;\n",
                     "}\n",
                     "\n",
                     "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                     "\n",
                     "#sk-container-id-11 a.estimator_doc_link {\n",
                     "  float: right;\n",
                     "  font-size: 1rem;\n",
                     "  line-height: 1em;\n",
                     "  font-family: monospace;\n",
                     "  background-color: var(--sklearn-color-background);\n",
                     "  border-radius: 1rem;\n",
                     "  height: 1rem;\n",
                     "  width: 1rem;\n",
                     "  text-decoration: none;\n",
                     "  /* unfitted */\n",
                     "  color: var(--sklearn-color-unfitted-level-1);\n",
                     "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
                     "  /* fitted */\n",
                     "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                     "  color: var(--sklearn-color-fitted-level-1);\n",
                     "}\n",
                     "\n",
                     "/* On hover */\n",
                     "#sk-container-id-11 a.estimator_doc_link:hover {\n",
                     "  /* unfitted */\n",
                     "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                     "  color: var(--sklearn-color-background);\n",
                     "  text-decoration: none;\n",
                     "}\n",
                     "\n",
                     "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
                     "  /* fitted */\n",
                     "  background-color: var(--sklearn-color-fitted-level-3);\n",
                     "}\n",
                     "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(importance_type=&#x27;gain&#x27;, n_jobs=-1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(importance_type=&#x27;gain&#x27;, n_jobs=-1, random_state=0)</pre></div> </div></div></div></div>"
                  ],
                  "text/plain": [
                     "LGBMClassifier(importance_type='gain', n_jobs=-1, random_state=0)"
                  ]
               },
               "execution_count": 105,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from lightgbm import LGBMClassifier\n",
            "\n",
            "lgbm = LGBMClassifier(random_state=0, n_jobs=-1, importance_type='gain')\n",
            "lgbm.fit(X_train_balanced, y_train_balanced)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 106,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "np.float64(0.9433748070111706)"
                  ]
               },
               "execution_count": 106,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "y_pred = lgbm.predict_proba(X_test)[:, 1]\n",
            "auroc = roc_auc_score(y_test, y_pred)\n",
            "\n",
            "auroc"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 107,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Solution is correct!\n"
               ]
            }
         ],
         "source": [
            "assert 0.9 <= auroc <= 0.97\n",
            "\n",
            "print(\"Solution is correct!\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Model LGBMClassifier wykorzystywujacy boosting jest o okolo ~3% lepszy od modelu Random Forest, pomimo ze nie przechodzil jeszcze tuningu hiperparametrow. Jest to bardzo dobry wynik.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "Boosting dzięki uczeniu na poprzednich drzewach redukuje nie tylko wariancję, ale też bias w błędzie, dzięki czemu może w wielu przypadkach osiągnąć lepsze rezultaty od lasu losowego. Do tego dzięki znakomitej implementacji LightGBM jest szybszy.\n",
            "\n",
            "Boosting jest jednak o wiele bardziej czuły na hiperparametry niż Random Forest. W szczególności bardzo łatwo go przeuczyć, a większość hiperparametrów, których jest dużo, wiąże się z regularyzacją modelu. To, że teraz poszło nam lepiej z domyślnymi, jest rzadkim przypadkiem.\n",
            "\n",
            "W związku z tym, że przestrzeń hiperparametrów jest duża, przeszukanie wszystkich kombinacji nie wchodzi w grę. Zamiast tego można wylosować zadaną liczbę zestawów hiperparametrów i tylko je sprawdzić - chociaż im więcej, tym lepsze wyniki powinniśmy dostać. Służy do tego `RandomizedSearchCV`. Co więcej, klasa ta potrafi próbkować rozkłady prawdopodobieństwa, a nie tylko sztywne listy wartości, co jest bardzo przydatne przy parametrach ciągłych.\n",
            "\n",
            "Hiperparametry LightGBMa są dobrze opisane w oficjalnej dokumentacji: [wersja krótsza](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier) i [wersja dłuższa](https://lightgbm.readthedocs.io/en/latest/Parameters.html). Jest ich dużo, więc nie będziemy ich tutaj omawiać. Jeżeli chodzi o ich dostrajanie w praktyce, to przydatny jest [oficjalny guide](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html) oraz dyskusje na Kaggle.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 8 (1.5 punktu)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Zaimplementuj random search dla LightGBMa (klasa `RandomizedSearchCV`):\n",
            "   - użyj tylu prób, na ile pozwalają twoje zasoby obliczeniowe, ale przynajmniej 30\n",
            "   - przeszukaj przestrzeń hiperparametrów:\n",
            "   ```python\n",
            "   param_grid = {\n",
            "       \"n_estimators\": [100, 250, 500],\n",
            "       \"learning_rate\": [0.05, 0.1, 0.2],\n",
            "       \"num_leaves\": [31, 48, 64],\n",
            "       \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
            "       \"subsample\": [0.8, 0.9, 1.0],\n",
            "   }\n",
            "   ```\n",
            "2. Wypisz znalezione optymalne hiperparametry.\n",
            "3. Wypisz raporty z klasyfikacji (funkcja `classification_report`), dla modelu LightGBM bez i z dostrajaniem hiperparametrów.\n",
            "4. Skomentuj różnicę precyzji (precision) i czułości (recall) między modelami bez i z dostrajaniem hiperparametrów. Czy jest to pożądane zjawisko w tym przypadku?\n",
            "5. Wartość ROC przypisz do zmiennej `auroc`.\n",
            "\n",
            "**Uwaga:**\n",
            "\n",
            "- koniecznie ustaw `verbose=-1` przy tworzeniu `LGBMClassifier`, żeby uniknąć kolosalnej ilości logów, która potrafi też wyłączyć Jupytera\n",
            "- pamiętaj o ustawieniu `importance_type`, `random_state=0` i `n_jobs`, oraz ewentualnie `verbose` w `RandomizedSearchCV` dla śledzenia przebiegu\n",
            "- istnieje możliwość, że ustawienie `n_jobs` dla grid searcha będzie szybsze niż dla samego LightGBM; odpowiada to tuningowi wielu klasyfikatorów równolegle, przy wolniejszym treningu pojedynczych klasyfikatorów\n",
            "- nie ustawiaj wszędzie `n_jobs=-1`, bo wtedy stworzysz więcej procesów niż rdzeni i spowodujesz thread contention\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "editable": true,
            "pycharm": {
               "is_executing": true,
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6404\n",
                  "[LightGBM] [Info] Number of positive: 6404, number of negative: 6405\n",
                  "[LightGBM] [Info] Number of positive: 6404, number of negative: 6405\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012198 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014006 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010603 seconds.\n",
                  "You can set `force_row_wise=true` to remove the overhead.\n",
                  "And if memory is not enough, you can set `force_col_wise=true`.\n",
                  "\n",
                  "[LightGBM] [Info] Start training from score 0.000156\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Start training from score -0.000156\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Start training from score -0.000156\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003143 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6404\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003715 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
                  "[LightGBM] [Info] Start training from score 0.000156\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.1, n_estimators=100, num_leaves=31, subsample=1.0; total time=   3.3s\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.1, n_estimators=100, num_leaves=31, subsample=1.0; total time=   3.4s\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.1, n_estimators=100, num_leaves=31, subsample=1.0; total time=   3.5s\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.1, n_estimators=100, num_leaves=31, subsample=1.0; total time=   3.5s\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6404\n",
                  "[LightGBM] [Info] Number of positive: 6404, number of negative: 6405\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156\n",
                  "[LightGBM] [Info] Start training from score -0.000156\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025870 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037950 seconds.\n",
                  "You can set `force_row_wise=true` to remove the overhead.\n",
                  "And if memory is not enough, you can set `force_col_wise=true`.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
                  "[LightGBM] [Info] Start training from score 0.000156\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.1, n_estimators=100, num_leaves=31, subsample=1.0; total time=   4.1s\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010532 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=250, num_leaves=31, subsample=0.9; total time=   6.9s\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005302 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.2, n_estimators=250, num_leaves=64, subsample=0.8; total time=  10.6s\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025455 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.2, n_estimators=250, num_leaves=64, subsample=0.8; total time=  10.8s\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of positive: 6405, number of negative: 6404\n",
                  "\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005407 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
                  "[LightGBM] [Info] Start training from score 0.000156\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=250, num_leaves=31, subsample=0.9; total time=   7.1s\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Number of positive: 6404, number of negative: 6405\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
                  "You can set `force_row_wise=true` to remove the overhead.\n",
                  "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12809, number of used features: 63[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Start training from score -0.000156\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[CV] END colsample_bytree=0.9, learning_rate=0.2, n_estimators=250, num_leaves=64, subsample=0.8; total time=  13.0s\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020721 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[CV] END colsample_bytree=0.8, learning_rate=0.1, n_estimators=250, num_leaves=31, subsample=0.9; total time=  11.5s\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Info] Number of positive: 6405, number of negative: 6405\n",
                  "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006356 seconds.\n",
                  "You can set `force_col_wise=true` to remove the overhead.\n",
                  "[LightGBM] [Info] Total Bins 16065\n",
                  "[LightGBM] [Info] Number of data points in the train set: 12810, number of used features: 63\n",
                  "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                  "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
               ]
            }
         ],
         "source": [
            "from sklearn.model_selection import RandomizedSearchCV\n",
            "from lightgbm import LGBMClassifier\n",
            "\n",
            "param_grid = {\n",
            "    \"n_estimators\": [100, 250, 500],\n",
            "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
            "    \"num_leaves\": [31, 48, 64],\n",
            "    \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
            "    \"subsample\": [0.8, 0.9, 1.0],\n",
            "}\n",
            "\n",
            "lgbm = LGBMClassifier(\n",
            "    random_state=0, importance_type='gain')\n",
            "\n",
            "rs = RandomizedSearchCV(lgbm, param_grid, scoring='roc_auc',\n",
            "                        random_state=0, n_iter=100, verbose=2, n_jobs=-1)\n",
            "\n",
            "rs.fit(X_train_balanced, y_train_balanced)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(rs.best_params_)\n",
            "\n",
            "y_pred = rs.predict_proba(X_test)[:, 1]\n",
            "auroc = roc_auc_score(y_test, y_pred)\n",
            "\n",
            "auroc"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 74,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [],
         "source": [
            "assert 0.9 <= auroc <= 0.99"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Pomimo zastosowania tuningu hiperparametrów, wynik nie uległ znacznej poprawie. Mogło się tak wydarzyć przez to ze mielismy szczescie, i domyslne parametry byly juz bardzo dobre, albo ze przestrzen hiperparametrow byla zbyt ograniczona i za malo zestawow bylo sprawdzonych. Nalezałoby wiec sprawdzic inny zestaw hiperparametrow, albo zwiekszyc liczbe iteracji w RandomizedSearchCV.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "**Boosting - podsumowanie**\n",
            "\n",
            "1. Model oparty o uczenie zespołowe\n",
            "2. Kolejne modele są dodawane sekwencyjnie i uczą się na błędach poprzedników\n",
            "3. Nauka typowo jest oparta o minimalizację funkcji kosztu (błędu), z użyciem spadku wzdłuż gradientu\n",
            "4. Wiodący model klasyfikacji dla danych tabelarycznych, z 2 głównymi implementacjami: XGBoost i LightGBM\n",
            "5. Liczne hiperparametry, wymagające odpowiednich metod dostrajania\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "## Wyjaśnialna AI\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": []
         },
         "source": [
            "W ostatnich latach zaczęto zwracać coraz większą uwagę na wpływ sztucznej inteligencji na społeczeństwo, a na niektórych czołowych konferencjach ML nawet obowiązkowa jest sekcja \"Social impact\" w artykułach naukowych. Typowo im lepszy model, tym bardziej złożony, a najpopularniejsze modele boostingu są z natury skomplikowane. Kiedy mają podejmować krytyczne decyzje, to musimy wiedzieć, czemu predykcja jest taka, a nie inna. Jest to poddziedzina uczenia maszynowego - **wyjaśnialna AI (explainable AI, XAI)**.\n",
            "\n",
            "Taka informacja jest cenna, bo dzięki temu lepiej wiemy, co robi model. Jest to ważne z kilku powodów:\n",
            "\n",
            "1. Wymogi prawne - wdrażanie algorytmów w ekonomii, prawie etc. ma coraz częściej konkretne wymagania prawne co do wyjaśnialności predykcji\n",
            "2. Dodatkowa wiedza dla użytkowników - często dodatkowe obserwacje co do próbek są ciekawe same w sobie i dają wiedzę użytkownikowi (często posiadającemu specjalistyczną wiedzę z dziedziny), czasem nawet bardziej niż sam model predykcyjny\n",
            "3. Analiza modelu - dodatkowa wiedza o wewnętrznym działaniu algorytmu pozwala go lepiej zrozumieć i ulepszyć wyniki, np. przez lepszy preprocessing danych\n",
            "\n",
            "W szczególności można ją podzielić na **globalną** oraz **lokalną interpretowalność (global / local interpretability)**. Ta pierwsza próbuje wyjaśnić, czemu ogólnie model działa tak, jak działa. Analizuje strukturę modelu oraz trendy w jego predykcjach, aby podsumować w prostszy sposób jego tok myślenia. Interpretowalność lokalna z kolei dotyczy predykcji dla konkretnych próbek - czemu dla danego przykładu model podejmuje dla niego taką, a nie inną decyzję o klasyfikacji.\n",
            "\n",
            "W szczególności podstawowym sposobem interpretowalności jest **ważność cech (feature importance)**. Wyznacza ona, jak ważne są poszczególne cechy:\n",
            "\n",
            "- w wariancie globalnym, jak mocno model opiera się na poszczególnych cechach\n",
            "- w wariancie lokalnym, jak mocno konkretne wartości cech wpłynęły na predykcję, i w jaki sposób\n",
            "\n",
            "Teraz będzie nas interesować globalna ważność cech. Dla modeli drzewiastych definiuje się ją bardzo prosto. Każdy podział w drzewie decyzyjnym wykorzystuje jakąś cechę, i redukuje z pomocą podziału funkcję kosztu (np. entropię) o określoną ilość. Dla drzewa decyzyjnego ważność to sumaryczna redukcja entropii, jaką udało się uzyskać za pomocą danej cechy. Dla lasów losowych i boostingu sumujemy te wartości dla wszystkich drzew. Alternatywnie można też użyć liczby splitów, w jakiej została użyta dana cecha, ale jest to mniej standardowe.\n",
            "\n",
            "Warto zauważyć, że taka ważność cech jest **względna**:\n",
            "\n",
            "- nie mówimy, jak bardzo ogólnie ważna jest jakaś cecha, tylko jak bardzo przydatna była dla naszego modelu w celu jego wytrenowania\n",
            "- ważność cech można tylko porównywać ze sobą, np. jedna jest 2 razy ważniejsza od drugiej; nie ma ogólnych progów ważności\n",
            "\n",
            "Ze względu na powyższe, ważności cech normalizuje się często do zakresu [0, 1] dla łatwiejszego porównywania.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "### Zadanie 9 (0.5 punktu)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "1. Wybierz 5 najważniejszych cech dla drzewa decyzyjnego. Przedstaw wyniki na poziomym wykresie słupkowym. Użyj czytelnych nazw cech ze zmiennej `feature_names`.\n",
            "2. Powtórz powyższe dla lasu losowego, oraz dla boostingu (tutaj znormalizuj wyniki - patrz uwaga niżej). Wybierz te hiperparametry, które dały wcześniej najlepsze wyniki.\n",
            "3. Skomentuj, czy wybrane cechy twoim zdaniem mają sens jako najważniejsze cechy.\n",
            "\n",
            "**Uwaga:** Scikit-learn normalizuje ważności do zakresu [0, 1], natomiast LightGBM nie. Musisz to znormalizować samodzielnie, dzieląc przez sumę.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 75,
         "metadata": {},
         "outputs": [],
         "source": [
            "from pandas import DataFrame\n",
            "\n",
            "\n",
            "def draw_feature_importances(importance_features: list, features_names: list, probes=5, normalize=False):\n",
            "    features_and_names = DataFrame([features_names, importance_features], index=[\n",
            "                                   'feature', 'importance']).T\n",
            "\n",
            "    features_and_names.sort_values(\n",
            "        by='importance', ascending=False, inplace=True)\n",
            "\n",
            "    if normalize:\n",
            "        features_and_names['importance'] /= features_and_names['importance'].sum()\n",
            "\n",
            "    _, ax = plt.subplots()\n",
            "    y_pos = np.arange(probes)\n",
            "\n",
            "    ax.barh(y_pos, features_and_names['importance'][:probes])\n",
            "    ax.set_yticks(y_pos, features_and_names['feature'][:probes])\n",
            "    ax.invert_yaxis()\n",
            "    ax.set_xlabel('Importance')\n",
            "    ax.set_title('Feature importance')\n",
            "\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [],
         "source": [
            "draw_feature_importances(tree.feature_importances_, feature_names)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "best_params = {'max_features': 0.2}\n",
            "forrest = RandomForestClassifier(\n",
            "    **best_params, criterion='entropy', random_state=0, n_estimators=500, n_jobs=-1)\n",
            "\n",
            "forrest.fit(X_train_balanced, y_train_balanced)\n",
            "\n",
            "draw_feature_importances(forrest.feature_importances_, feature_names)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "best_params = {'subsample': 0.8, 'num_leaves': 31,\n",
            "               'n_estimators': 500, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
            "lgbm = LGBMClassifier(random_state=0, n_jobs=-1,\n",
            "                      importance_type='gain', **best_params)\n",
            "\n",
            "lgbm.fit(X_train_balanced, y_train_balanced)\n",
            "\n",
            "draw_feature_importances(lgbm.feature_importances_,\n",
            "                         feature_names, normalize=True)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Na samym szczycie są cechy takie jak zysk i wydatki, które powinny mieć duzy wpływ na to czy firma zbankrutuje więc myśle ze jak najbardziej ma to sens.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Dla zainteresowanych\n",
            "\n",
            "Najpopularniejszym podejściem do interpretowalności lokalnych jest **SHAP (SHapley Additive exPlanations)**, metoda oparta o kooperatywną teorię gier. Traktuje się cechy modelu jak zbiór graczy, podzielonych na dwie drużyny (koalicje): jedna chce zaklasyfikować próbkę jako negatywną, a druga jako pozytywną. O ostatecznej decyzji decyduje model, który wykorzystuje te wartości cech. Powstaje pytanie - w jakim stopniu wartości cech przyczyniły się do wyniku swojej drużyny? Można to obliczyć jako wartości Shapleya (Shapley values), które dla modeli ML oblicza algorytm SHAP. Ma on bardzo znaczące, udowodnione matematycznie zalety, a dodatkowo posiada wyjątkowo efektywną implementację dla modeli drzewiastych oraz dobre wizualizacje.\n",
            "\n",
            "Bardzo intuicyjnie, na prostym przykładzie, SHAPa wyjaśnia [pierwsza część tego artykułu](https://iancovert.com/blog/understanding-shap-sage/). Dobrze i dość szczegółówo SHAPa wyjaśnia jego autor [w tym filmie](https://www.youtube.com/watch?v=-taOhqkiuIo).\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "pycharm": {
               "name": "#%% md\n"
            }
         },
         "source": [
            "**Wyjaśnialna AI - podsumowanie**\n",
            "\n",
            "1. Problem zrozumienia, jak wnioskuje model i czemu podejmuje dane decyzje\n",
            "2. Ważne zarówno z perspektywy data scientist'a, jak i użytkowników systemu\n",
            "3. Można wyjaśniać model lokalnie (konkretne predykcje) lub globalnie (wpływ poszczególnych cech)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "## Zadanie 10 dla chętnych (3 punkty)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%% md\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "source": [
            "Dokonaj selekcji cech, usuwając 20% najsłabszych cech. Może się tu przydać klasa `SelectPercentile`. Czy Random Forest i LightGBM (bez dostrajania hiperparametrów, dla uproszczenia) wytrenowane bez najsłabszych cech dają lepszy wynik (AUROC lub innej metryki)?\n",
            "\n",
            "Wykorzystaj po 1 algorytmie z 3 grup algorytmów selekcji cech:\n",
            "\n",
            "1. Filter methods - mierzymy ważność każdej cechy niezależnie, za pomocą pewnej miary (typowo ze statystyki lub teorii informacji), a potem odrzucamy (filtrujemy) te o najniższej ważności. Są to np. `chi2` i `mutual_info_classif` z pakietu `sklearn.feature_selection`.\n",
            "2. Embedded methods - klasyfikator sam zwraca ważność cech, jest jego wbudowaną cechą (stąd nazwa). Jest to w szczególności właściwość wszystkich zespołowych klasyfikatorów drzewiastych. Mają po wytrenowaniu atrybut `feature_importances_`.\n",
            "3. Wrapper methods - algorytmy wykorzystujące w środku używany model (stąd nazwa), mierzące ważność cech za pomocą ich wpływu na jakość klasyfikatora. Jest to np. recursive feature elimination (klasa `RFE`). W tym algorytmie trenujemy klasyfikator na wszystkich cechach, wyrzucamy najsłabszą, trenujemy znowu i tak dalej.\n",
            "\n",
            "Typowo metody filter są najszybsze, ale dają najsłabszy wynik, natomiast metody wrapper są najwolniejsze i dają najlepszy wynik. Metody embedded są gdzieś pośrodku.\n",
            "\n",
            "Dla zainteresowanych, inne znane i bardzo dobre algorytmy:\n",
            "\n",
            "- Relief (filter method) oraz warianty, szczególnie ReliefF, SURF i MultiSURF (biblioteka `ReBATE`): [Wikipedia](<https://en.wikipedia.org/wiki/Relief_(feature_selection)>), [artykuł \"Benchmarking Relief-Based Feature Selection Methods\"](https://www.researchgate.net/publication/321307194_Benchmarking_Relief-Based_Feature_Selection_Methods)\n",
            "- Boruta (wrapper method), stworzony na Uniwersytecie Warszawskim, łączący Random Forest oraz testy statystyczne (biblioteka `boruta_py`): [link 1](https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a), [link 2](https://danielhomola.com/feature%20selection/phd/borutapy-an-all-relevant-feature-selection-method/)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "editable": true,
            "pycharm": {
               "name": "#%%\n"
            },
            "slideshow": {
               "slide_type": ""
            },
            "tags": [
               "ex"
            ]
         },
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "jupytext": {
         "formats": "ipynb,py:percent"
      },
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.7"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
